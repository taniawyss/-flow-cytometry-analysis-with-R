{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home Life scientists often use commercial software such as FlowJo or the OMIQ platform to analyze flow cytometry data. These tools are useful for initial and basic analysis, but do not allow for more advanced or flexible analyses, nor for the establishment of pipelines and reports. On the other hand, R is statistical software that allows for very flexible analysis, customizable pipeline creation and generation of reports. The \u201cAnalysis of flow cytometry data with R\u201d training that is proposed will focus on using R to analyze flow cytometry data. Flow cytometry data that can be analyzed with R includes classical multicolor flow cytometry, spectral flow cytometry, and CyTOF. This course will teach experts in flow cytometry how to run data analysis, develop pipelines and create reports using the open-source R software. This course is proposed by the Translational Data Science Facility of the SIB Swiss Institute of Bioinformatics in Lausanne. Prerequisite Participants should already have a general knowledge of flow cytometry. The course will focus on data analysis, but a brief introduction to flow cytometry will be given. To fully benefit from this course, participants should have basic knowledge of R, such as installing packages, running commands, importing and manipulating data within R, and basic plotting functions. These prerequisites can be obtained by attending the First steps with R course organized by the SIB. Alternatively, participants can self-learn R using our Introduction to R page specifically designed for participants of the \u201cFlow Cytometry analysis with R\u201d course. Asking questions During lectures, you are encouraged to ask questions using the Zoom functionality. Find the buttons in the participants list (\u2018Participants\u2019 button): Alternatively, (depending on your zoom version or OS) use the \u2018Reactions\u2019 button:","title":"Home"},{"location":"#home","text":"Life scientists often use commercial software such as FlowJo or the OMIQ platform to analyze flow cytometry data. These tools are useful for initial and basic analysis, but do not allow for more advanced or flexible analyses, nor for the establishment of pipelines and reports. On the other hand, R is statistical software that allows for very flexible analysis, customizable pipeline creation and generation of reports. The \u201cAnalysis of flow cytometry data with R\u201d training that is proposed will focus on using R to analyze flow cytometry data. Flow cytometry data that can be analyzed with R includes classical multicolor flow cytometry, spectral flow cytometry, and CyTOF. This course will teach experts in flow cytometry how to run data analysis, develop pipelines and create reports using the open-source R software. This course is proposed by the Translational Data Science Facility of the SIB Swiss Institute of Bioinformatics in Lausanne.","title":"Home"},{"location":"#prerequisite","text":"Participants should already have a general knowledge of flow cytometry. The course will focus on data analysis, but a brief introduction to flow cytometry will be given. To fully benefit from this course, participants should have basic knowledge of R, such as installing packages, running commands, importing and manipulating data within R, and basic plotting functions. These prerequisites can be obtained by attending the First steps with R course organized by the SIB. Alternatively, participants can self-learn R using our Introduction to R page specifically designed for participants of the \u201cFlow Cytometry analysis with R\u201d course.","title":"Prerequisite"},{"location":"#asking-questions","text":"During lectures, you are encouraged to ask questions using the Zoom functionality. Find the buttons in the participants list (\u2018Participants\u2019 button): Alternatively, (depending on your zoom version or OS) use the \u2018Reactions\u2019 button:","title":"Asking questions"},{"location":"flowCyt/course_schedule/","text":"We will start every day at 9 am and end at 5pm. start end topic 10:30 10:50 Coffee break! 12:30 13:30 Lunch break! 15:30 15:50 Coffee break!","title":"Course schedule"},{"location":"flowCyt/links/","text":"Here we provide some additional links A practical workflow for spectral flow cytometry data analysis with R We found inspiration for this course in this publication den Braanker et al, 2021, Frontiers in Immunology Comparative analysis of dimension reduction methods for cytometry by time-of-flight data From the abstract: \u201d Here, we benchmark the performances of 21 DR methods on 110 real and 425 synthetic CyTOF samples. We find that less well-known methods like SAUCIE, SQuaD-MDS, and scvis are the overall best performers. In particular, SAUCIE and scvis are well balanced, SQuaD-MDS excels at structure preservation, whereas UMAP has great downstream analysis performance. We also find that t-SNE (along with SQuad-MDS/t-SNE Hybrid) possesses the best local structure preservation. Nevertheless, there is a high level of complementarity between these tools, so the choice of method should depend on the underlying data structure and the analytical needs. \u201c Wang et al, 2023 Orchestrating single-cell analysis with Bioconductor Code mostly developed for single-cell RNA seq analysis, but some of the concepts explained apply to flow cytometry data analysis also, such as the singleCellExperiment object described in Chapter 4. OSCA book Understanding UMAP A website where you can play with the parameters and see how the 2D projection of an original data set changes https://pair-code.github.io/understanding-umap/ Understanding tSNE A website where you can play with the parameters and see how the 2D projection of an original data set changes https://distill.pub/2016/misread-tsne/ R for Data Science Book Book (2nd edition) by Hadley Wickham (a very active R developer), Mine \u00c7etinkaya-Rundel and Garrett Grolemund. The book makes heavy use of the tidyverse , which is a collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. ggplot2 is part of the tidyverse packages. https://r4ds.hadley.nz/ ggplot2 tutorial https://ggplot2.tidyverse.org/ R-charts A site that has been created to be a reference for learning how to create charts in R as well as a place to look for inspiration. Code examples to create plots with base R, ggplot2. Color charts with R color name vs HEX equivalent. https://r-charts.com/ R Markdown A useful resource is RStudio\u2019s R Markdown tutorial . For tweaking your reports, such as chosing different output formats, or hiding or showing the code within the report, we recommend that you consult the R markdown documentation provided in this Definite guide eBook . Go further with the R Markdown Cookbook . Cheatsheets Several cheatsheets available for different packages, eg R Markdown, ggplot2, RStudio,\u2026","title":"Useful links"},{"location":"flowCyt/links/#a-practical-workflow-for-spectral-flow-cytometry-data-analysis-with-r","text":"We found inspiration for this course in this publication den Braanker et al, 2021, Frontiers in Immunology","title":"A practical workflow for spectral flow cytometry data analysis with R"},{"location":"flowCyt/links/#comparative-analysis-of-dimension-reduction-methods-for-cytometry-by-time-of-flight-data","text":"From the abstract: \u201d Here, we benchmark the performances of 21 DR methods on 110 real and 425 synthetic CyTOF samples. We find that less well-known methods like SAUCIE, SQuaD-MDS, and scvis are the overall best performers. In particular, SAUCIE and scvis are well balanced, SQuaD-MDS excels at structure preservation, whereas UMAP has great downstream analysis performance. We also find that t-SNE (along with SQuad-MDS/t-SNE Hybrid) possesses the best local structure preservation. Nevertheless, there is a high level of complementarity between these tools, so the choice of method should depend on the underlying data structure and the analytical needs. \u201c Wang et al, 2023","title":"Comparative analysis of dimension reduction methods for cytometry by time-of-flight data"},{"location":"flowCyt/links/#orchestrating-single-cell-analysis-with-bioconductor","text":"Code mostly developed for single-cell RNA seq analysis, but some of the concepts explained apply to flow cytometry data analysis also, such as the singleCellExperiment object described in Chapter 4. OSCA book","title":"Orchestrating single-cell analysis with Bioconductor"},{"location":"flowCyt/links/#understanding-umap","text":"A website where you can play with the parameters and see how the 2D projection of an original data set changes https://pair-code.github.io/understanding-umap/","title":"Understanding UMAP"},{"location":"flowCyt/links/#understanding-tsne","text":"A website where you can play with the parameters and see how the 2D projection of an original data set changes https://distill.pub/2016/misread-tsne/","title":"Understanding tSNE"},{"location":"flowCyt/links/#r-for-data-science-book","text":"Book (2nd edition) by Hadley Wickham (a very active R developer), Mine \u00c7etinkaya-Rundel and Garrett Grolemund. The book makes heavy use of the tidyverse , which is a collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. ggplot2 is part of the tidyverse packages. https://r4ds.hadley.nz/","title":"R for Data Science Book"},{"location":"flowCyt/links/#ggplot2-tutorial","text":"https://ggplot2.tidyverse.org/","title":"ggplot2 tutorial"},{"location":"flowCyt/links/#r-charts","text":"A site that has been created to be a reference for learning how to create charts in R as well as a place to look for inspiration. Code examples to create plots with base R, ggplot2. Color charts with R color name vs HEX equivalent. https://r-charts.com/","title":"R-charts"},{"location":"flowCyt/links/#r-markdown","text":"A useful resource is RStudio\u2019s R Markdown tutorial . For tweaking your reports, such as chosing different output formats, or hiding or showing the code within the report, we recommend that you consult the R markdown documentation provided in this Definite guide eBook . Go further with the R Markdown Cookbook .","title":"R Markdown"},{"location":"flowCyt/links/#cheatsheets","text":"Several cheatsheets available for different packages, eg R Markdown, ggplot2, RStudio,\u2026","title":"Cheatsheets"},{"location":"flowCyt/material/","text":"Slides of lectures Day 1 - Starting to work with flow cytometry data, Transformation, Quality control Download slides Day 2 - Dimensionality reduction, Clustering and annotation, Differential testing Download slides Day 3 - Normalization (batch correction), Manual gating, Automated gating, Phenotype discovery Download slides Day 4 - R Markdown Download slides Day 5 Download slides Data for exercises Please note that the data size is very big: 2.3GB. It may take a while to download. Find the link here .","title":"Material"},{"location":"flowCyt/material/#slides-of-lectures","text":"","title":"Slides of lectures"},{"location":"flowCyt/material/#day-1-starting-to-work-with-flow-cytometry-data-transformation-quality-control","text":"Download slides","title":"Day 1 - Starting to work with flow cytometry data, Transformation, Quality control"},{"location":"flowCyt/material/#day-2-dimensionality-reduction-clustering-and-annotation-differential-testing","text":"Download slides","title":"Day 2 - Dimensionality reduction, Clustering and annotation, Differential testing"},{"location":"flowCyt/material/#day-3-normalization-batch-correction-manual-gating-automated-gating-phenotype-discovery","text":"Download slides","title":"Day 3 - Normalization (batch correction), Manual gating, Automated gating, Phenotype discovery"},{"location":"flowCyt/material/#day-4-r-markdown","text":"Download slides","title":"Day 4 - R Markdown"},{"location":"flowCyt/material/#day-5","text":"Download slides","title":"Day 5"},{"location":"flowCyt/material/#data-for-exercises","text":"Please note that the data size is very big: 2.3GB. It may take a while to download. Find the link here .","title":"Data for exercises"},{"location":"flowCyt/precourse/","text":"R and RStudio Previous knowledge / Competencies We expect participants to have previous knowledge in: R beginner level (Rstudio, install a library, data frame manipulation, import data from csv file). An introduction to R is available here . Technical This course will be streamed, you are thus required to have your own computer with an internet connection, and with latest the version of R and the free version of RStudio installed. Admin rights may be needed to install the necessary packages. The packages we will need are hosted on CRAN , Bioconductor and Github . You can install the necessary packages using: ################################# # Non-CRAN package installation # ################################# install.packages ( \"devtools\" ) install.packages ( \"BiocManager\" ) ############### # R markdown # ############### install.packages ( \"knitr\" ) install.packages ( \"rmarkdown\" ) install.packages ( \"pander\" ) ##################### # Excel files # ##################### install.packages ( \"readxl\" ) install.packages ( \"xlsx\" ) install.packages ( \"WriteXLS\" ) ################# # Visualization # ################# install.packages ( \"ggplot2\" ) BiocManager :: install ( \"ggcyto\" ) install.packages ( \"manipulate\" ) install.packages ( \"ggrepel\" ) install.packages ( \"ggpubr\" ) install.packages ( \"RColorBrewer\" ) install.packages ( \"gridExtra\" ) install.packages ( \"cowplot\" ) install.packages ( \"ggsignif\" ) BiocManager :: install ( \"plotly\" ) install.packages ( \"ggridges\" ) install.packages ( \"scales\" ) BiocManager :: install ( \"ComplexHeatmap\" ) install.packages ( \"circlize\" ) install.packages ( \"cowplot\" ) ################# # Data handling # ################# install.packages ( \"reshape2\" ) install.packages ( \"matrixStats\" ) install.packages ( \"tidyverse\" ) install.packages ( \"dplyr\" ) install.packages ( \"tibble\" ) ############################################### # Statistical functions # ############################################### install.packages ( \"lme4\" ) install.packages ( \"multcomp\" ) install.packages ( \"rstatix\" ) install.packages ( \"DescTools\" ) install.packages ( \"statmod\" ) BiocManager :: install ( \"edgeR\" ) install.packages ( \"MASS\" ) BiocManager :: install ( \"diffcyt\" ) install.packages ( 'sfsmisc' ) install.packages ( \"rms\" ) ######################################### # Libraries for flow cytometry analysis # ######################################### BiocManager :: install ( \"flowCore\" ) BiocManager :: install ( \"flowWorkspace\" ) BiocManager :: install ( \"flowWorkspaceData\" ) BiocManager :: install ( \"flowDensity\" ) BiocManager :: install ( \"MetaCyto\" ) BiocManager :: install ( \"scDataviz\" ) BiocManager :: install ( \"flowViz\" ) BiocManager :: install ( \"flowVS\" ) BiocManager :: install ( \"flowAI\" ) BiocManager :: install ( \"PeacoQC\" ) BiocManager :: install ( \"flowClean\" ) BiocManager :: install ( \"CATALYST\" ) devtools :: install_github ( 'saeyslab/CytoNorm' ) BiocManager :: install ( \"SingleCellExperiment\" ) install.packages ( \"uwot\" ) BiocManager :: install ( \"FlowSOM\" ) BiocManager :: install ( \"ConsensusClusterPlus\" ) install.packages ( \"Rtsne\" ) BiocManager :: install ( \"scater\" ) devtools :: install_github ( \"RGLab/scamp\" ) devtools :: install_github ( \"RGLab/FAUST\" ) ############################ # Survival analysis # ############################ install.packages ( \"survival\" ) install.packages ( \"survminer\" ) ############################ # Gating # ############################ BiocManager :: install ( \"flowClust\" ) BiocManager :: install ( \"CytoML\" ) BiocManager :: install ( \"openCyto\" ) After installation, packages can be loaded using: ################################# # Non-CRAN package installation # ################################# # install packages library ( devtools ) # install.packages(\"devtools\") library ( BiocManager ) # install.packages(\"BiocManager\") ############### # R markdown # ############### library ( knitr ) # install.packages(\"knitr\") library ( rmarkdown ) # install.packages(\"rmarkdown\") library ( pander ) # install.packages(\"pander\") ##################### # Excel files # ##################### library ( readxl ) # install.packages(\"readxl\") library ( xlsx ) # install.packages(\"xlsx\") library ( WriteXLS ) # install.packages(\"WriteXLS\") ################# # Visualization # ################# library ( ggplot2 ) # install.packages(\"ggplot2\") library ( ggcyto ) # BiocManager::install(\"ggcyto\") library ( manipulate ) # install.packages(\"manipulate\") library ( ggrepel ) # install.packages(\"ggrepel\") library ( ggpubr ) # install.packages(\"ggpubr\") library ( RColorBrewer ) # install.packages(\"RColorBrewer\") library ( gridExtra ) # install.packages(\"gridExtra\") library ( cowplot ) # install.packages(\"cowplot\") library ( ggsignif ) # install.packages(\"ggsignif\") library ( plotly ) # BiocManager::install(\"plotly\") library ( ggridges ) # install.packages(\"ggridges\") library ( scales ) # install.packages(\"scales\") library ( ComplexHeatmap ) # BiocManager::install(\"ComplexHeatmap\") library ( circlize ) # install.packages(\"circlize\") library ( cowplot ) # install.packages(\"cowplot\") ################# # Data handling # ################# library ( reshape2 ) # install.packages(\"reshape2\") library ( matrixStats ) # install.packages(\"matrixStats\") library ( tidyverse ) # install.packages(\"tidyverse\") library ( dplyr ) # install.packages(\"dplyr\") library ( tibble ) # install.packages(\"tibble\") ############################################### # Statistical functions # ############################################### library ( lme4 ) # install.packages(\"lme4\") library ( multcomp ) # install.packages(\"multcomp\") library ( rstatix ) # install.packages(\"rstatix\") library ( DescTools ) # install.packages(\"DescTools\") library ( statmod ) # install.packages(\"statmod\") library ( edgeR ) # BiocManager::install(\"edgeR\") library ( MASS ) # install.packages(\"MASS\") library ( diffcyt ) # BiocManager::install(\"diffcyt\") library ( sfsmisc ) # install.packages('sfsmisc') library ( rms ) # install.packages(\"rms\") ######################################### # Libraries for flow cytometry analysis # ######################################### library ( flowCore ) # BiocManager::install(\"flowCore\") library ( flowWorkspace ) # BiocManager::install(\"flowWorkspace\") library ( flowWorkspaceData ) # BiocManager::install(\"flowWorkspaceData\") library ( flowDensity ) # BiocManager::install(\"flowDensity\") library ( MetaCyto ) # BiocManager::install(\"MetaCyto\") library ( scDataviz ) # BiocManager::install(\"scDataviz\") library ( flowViz ) # BiocManager::install(\"flowViz\") library ( flowVS ) # BiocManager::install(\"flowVS\") library ( flowAI ) # BiocManager::install(\"flowAI\") library ( PeacoQC ) # BiocManager::install(\"PeacoQC\") library ( \"flowClean\" ) # BiocManager::install(\"flowClean\") library ( CATALYST ) # BiocManager::install(\"CATALYST\") library ( CytoNorm ) # install_github('saeyslab/CytoNorm') library ( SingleCellExperiment ) # BiocManager::install(\"SingleCellExperiment\") library ( uwot ) # install.packages(\"uwot\") library ( FlowSOM ) # BiocManager::install(\"FlowSOM\") library ( ConsensusClusterPlus ) # BiocManager::install(\"ConsensusClusterPlus\") library ( Rtsne ) # install.packages(\"Rtsne\") library ( scater ) # BiocManager::install(\"scater\") library ( scamp ) # devtools::install_github(\"RGLab/scamp\") library ( faust ) # devtools::install_github(\"RGLab/FAUST\") ############################ # Survival analysis # ############################ library ( survival ) # install.packages(\"survival\") library ( survminer ) # install.packages(\"survminer\") ############################ # Gating # ############################ library ( flowClust ) # BiocManager::install(\"flowClust\") library ( CytoML ) # BiocManager::install(\"CytoML\") library ( openCyto ) # BiocManager::install(\"openCyto\")","title":"Precourse preparations"},{"location":"flowCyt/precourse/#r-and-rstudio","text":"","title":"R and RStudio"},{"location":"flowCyt/precourse/#previous-knowledge-competencies","text":"We expect participants to have previous knowledge in: R beginner level (Rstudio, install a library, data frame manipulation, import data from csv file). An introduction to R is available here .","title":"Previous knowledge / Competencies"},{"location":"flowCyt/precourse/#technical","text":"This course will be streamed, you are thus required to have your own computer with an internet connection, and with latest the version of R and the free version of RStudio installed. Admin rights may be needed to install the necessary packages. The packages we will need are hosted on CRAN , Bioconductor and Github . You can install the necessary packages using: ################################# # Non-CRAN package installation # ################################# install.packages ( \"devtools\" ) install.packages ( \"BiocManager\" ) ############### # R markdown # ############### install.packages ( \"knitr\" ) install.packages ( \"rmarkdown\" ) install.packages ( \"pander\" ) ##################### # Excel files # ##################### install.packages ( \"readxl\" ) install.packages ( \"xlsx\" ) install.packages ( \"WriteXLS\" ) ################# # Visualization # ################# install.packages ( \"ggplot2\" ) BiocManager :: install ( \"ggcyto\" ) install.packages ( \"manipulate\" ) install.packages ( \"ggrepel\" ) install.packages ( \"ggpubr\" ) install.packages ( \"RColorBrewer\" ) install.packages ( \"gridExtra\" ) install.packages ( \"cowplot\" ) install.packages ( \"ggsignif\" ) BiocManager :: install ( \"plotly\" ) install.packages ( \"ggridges\" ) install.packages ( \"scales\" ) BiocManager :: install ( \"ComplexHeatmap\" ) install.packages ( \"circlize\" ) install.packages ( \"cowplot\" ) ################# # Data handling # ################# install.packages ( \"reshape2\" ) install.packages ( \"matrixStats\" ) install.packages ( \"tidyverse\" ) install.packages ( \"dplyr\" ) install.packages ( \"tibble\" ) ############################################### # Statistical functions # ############################################### install.packages ( \"lme4\" ) install.packages ( \"multcomp\" ) install.packages ( \"rstatix\" ) install.packages ( \"DescTools\" ) install.packages ( \"statmod\" ) BiocManager :: install ( \"edgeR\" ) install.packages ( \"MASS\" ) BiocManager :: install ( \"diffcyt\" ) install.packages ( 'sfsmisc' ) install.packages ( \"rms\" ) ######################################### # Libraries for flow cytometry analysis # ######################################### BiocManager :: install ( \"flowCore\" ) BiocManager :: install ( \"flowWorkspace\" ) BiocManager :: install ( \"flowWorkspaceData\" ) BiocManager :: install ( \"flowDensity\" ) BiocManager :: install ( \"MetaCyto\" ) BiocManager :: install ( \"scDataviz\" ) BiocManager :: install ( \"flowViz\" ) BiocManager :: install ( \"flowVS\" ) BiocManager :: install ( \"flowAI\" ) BiocManager :: install ( \"PeacoQC\" ) BiocManager :: install ( \"flowClean\" ) BiocManager :: install ( \"CATALYST\" ) devtools :: install_github ( 'saeyslab/CytoNorm' ) BiocManager :: install ( \"SingleCellExperiment\" ) install.packages ( \"uwot\" ) BiocManager :: install ( \"FlowSOM\" ) BiocManager :: install ( \"ConsensusClusterPlus\" ) install.packages ( \"Rtsne\" ) BiocManager :: install ( \"scater\" ) devtools :: install_github ( \"RGLab/scamp\" ) devtools :: install_github ( \"RGLab/FAUST\" ) ############################ # Survival analysis # ############################ install.packages ( \"survival\" ) install.packages ( \"survminer\" ) ############################ # Gating # ############################ BiocManager :: install ( \"flowClust\" ) BiocManager :: install ( \"CytoML\" ) BiocManager :: install ( \"openCyto\" ) After installation, packages can be loaded using: ################################# # Non-CRAN package installation # ################################# # install packages library ( devtools ) # install.packages(\"devtools\") library ( BiocManager ) # install.packages(\"BiocManager\") ############### # R markdown # ############### library ( knitr ) # install.packages(\"knitr\") library ( rmarkdown ) # install.packages(\"rmarkdown\") library ( pander ) # install.packages(\"pander\") ##################### # Excel files # ##################### library ( readxl ) # install.packages(\"readxl\") library ( xlsx ) # install.packages(\"xlsx\") library ( WriteXLS ) # install.packages(\"WriteXLS\") ################# # Visualization # ################# library ( ggplot2 ) # install.packages(\"ggplot2\") library ( ggcyto ) # BiocManager::install(\"ggcyto\") library ( manipulate ) # install.packages(\"manipulate\") library ( ggrepel ) # install.packages(\"ggrepel\") library ( ggpubr ) # install.packages(\"ggpubr\") library ( RColorBrewer ) # install.packages(\"RColorBrewer\") library ( gridExtra ) # install.packages(\"gridExtra\") library ( cowplot ) # install.packages(\"cowplot\") library ( ggsignif ) # install.packages(\"ggsignif\") library ( plotly ) # BiocManager::install(\"plotly\") library ( ggridges ) # install.packages(\"ggridges\") library ( scales ) # install.packages(\"scales\") library ( ComplexHeatmap ) # BiocManager::install(\"ComplexHeatmap\") library ( circlize ) # install.packages(\"circlize\") library ( cowplot ) # install.packages(\"cowplot\") ################# # Data handling # ################# library ( reshape2 ) # install.packages(\"reshape2\") library ( matrixStats ) # install.packages(\"matrixStats\") library ( tidyverse ) # install.packages(\"tidyverse\") library ( dplyr ) # install.packages(\"dplyr\") library ( tibble ) # install.packages(\"tibble\") ############################################### # Statistical functions # ############################################### library ( lme4 ) # install.packages(\"lme4\") library ( multcomp ) # install.packages(\"multcomp\") library ( rstatix ) # install.packages(\"rstatix\") library ( DescTools ) # install.packages(\"DescTools\") library ( statmod ) # install.packages(\"statmod\") library ( edgeR ) # BiocManager::install(\"edgeR\") library ( MASS ) # install.packages(\"MASS\") library ( diffcyt ) # BiocManager::install(\"diffcyt\") library ( sfsmisc ) # install.packages('sfsmisc') library ( rms ) # install.packages(\"rms\") ######################################### # Libraries for flow cytometry analysis # ######################################### library ( flowCore ) # BiocManager::install(\"flowCore\") library ( flowWorkspace ) # BiocManager::install(\"flowWorkspace\") library ( flowWorkspaceData ) # BiocManager::install(\"flowWorkspaceData\") library ( flowDensity ) # BiocManager::install(\"flowDensity\") library ( MetaCyto ) # BiocManager::install(\"MetaCyto\") library ( scDataviz ) # BiocManager::install(\"scDataviz\") library ( flowViz ) # BiocManager::install(\"flowViz\") library ( flowVS ) # BiocManager::install(\"flowVS\") library ( flowAI ) # BiocManager::install(\"flowAI\") library ( PeacoQC ) # BiocManager::install(\"PeacoQC\") library ( \"flowClean\" ) # BiocManager::install(\"flowClean\") library ( CATALYST ) # BiocManager::install(\"CATALYST\") library ( CytoNorm ) # install_github('saeyslab/CytoNorm') library ( SingleCellExperiment ) # BiocManager::install(\"SingleCellExperiment\") library ( uwot ) # install.packages(\"uwot\") library ( FlowSOM ) # BiocManager::install(\"FlowSOM\") library ( ConsensusClusterPlus ) # BiocManager::install(\"ConsensusClusterPlus\") library ( Rtsne ) # install.packages(\"Rtsne\") library ( scater ) # BiocManager::install(\"scater\") library ( scamp ) # devtools::install_github(\"RGLab/scamp\") library ( faust ) # devtools::install_github(\"RGLab/FAUST\") ############################ # Survival analysis # ############################ library ( survival ) # install.packages(\"survival\") library ( survminer ) # install.packages(\"survminer\") ############################ # Gating # ############################ library ( flowClust ) # BiocManager::install(\"flowClust\") library ( CytoML ) # BiocManager::install(\"CytoML\") library ( openCyto ) # BiocManager::install(\"openCyto\")","title":"Technical"},{"location":"flowCyt/day1/exercises_d1/","text":"In this section, you will find the R code that we will use during the course. We will explain the code and output during correction of the exercises. Starting to work with flow cytometry data in R - packages One package that provides data structures and basic functions to deal with flow cytometry data is flowCore . flowCore allows to import data contained within a FCS file and store it in a flowFrame object. Data combined from several FCS files are imported and stored in a flowSet object. Packages that provide functions for automatic quality control are flowAI and PeacoQC . For visualization, the package ggcyto provides plotting functions as an interface to ggplot2 plots using flowFrame or flowSet objects. One example is the autoplot() function. Another package available for visualization is flowViz , which includes the densityplot() function. Let\u2019s practice - 1 In this exercise we will use a 36-color spectral flow cytometry dataset from a study performed in the context of Covid-19 research. Only a subset from 5 healthy donors will be used. For each healthy donors, there are three time points, as indicated in the FCS file names. Data was downloaded through the Flow Repository database (FR-FCM-Z3WR) . FCS files were pre-gated on live CD3+CD19- T cells in FlowJo. Create a new script in which you will: 1) Import the FCS files (within course_datasets/FR_FCM_Z3WR/) into a flowSet. Do not transform or truncate the values. 2) Create a data frame with the list of channels and corresponding antigens, and view it. Hint: get the antigens from the parameters of one of the flowFrame in the set 3) Add a new column to the phenotypic data with the time point of the sample. View the phenotypic data 4) Convert the channel names in the expression matrices to the corresponding antigen names (where applicable). 5) Create a bivariate density plot showing \u00abFSC-H\u00bb againts \u00abHLA-DR\u00bb for all samples from day 0. Apply a flowJo inverse hyperbolic sine scale to the y axis (\u00abHLA-DR\u00bb) Answer # load libraries library ( flowCore ) library ( ggcyto ) # 1) Import the FCS files (course_datasets/FR_FCM_Z3WR/). # Do not transform or truncate the values. # path to the directory (folder) with the fcs files fcs.dir <- file.path ( \"course_datasets/FR_FCM_Z3WR/\" ) # read fcs files into a flowSet fcs_data <- flowCore :: read.flowSet ( path = fcs.dir , pattern = \"*.fcs\" , transformation = FALSE , truncate_max_range = FALSE ) # Explore the object: fcs_data summary ( fcs_data [[ 1 ]]) #2) Create a data frame with the list of channels and corresponding antigens, and show it. #Hint: get the antigens from the parameters of one of the flowFrame in the set channels <- colnames ( fcs_data ) antigen <- pData ( parameters ( fcs_data [[ 1 ]])) $ desc panel <- data.frame ( channels = channels , antigen = antigen ) # show the panel panel # write panel to csv file write.csv ( panel , file = \"course_datasets/FR_FCM_Z3WR/panel.csv\" , quote = FALSE , row.names = FALSE ) #3) Add a new column to the phenotypic data with the time point of the sample # check sample names sampleNames ( fcs_data ) # [1] \"0E1F8E_0.fcs\" \"0E1F8E_14.fcs\" \"0E1F8E_7.fcs\" \"180E1A_0.fcs\" \"180E1A_14.fcs\" \"180E1A_7.fcs\" # [7] \"1A9B20_0.fcs\" \"1A9B20_14.fcs\" \"1A9B20_7.fcs\" \"61BBAD_0.fcs\" \"61BBAD_14.fcs\" \"61BBAD_7.fcs\" # [13] \"61BBAD_0.fcs\" \"61BBAD_14.fcs\" \"61BBAD_7.fcs\" # add column with time point pData ( fcs_data ) $ time_point <- rep ( c ( \"D0\" , \"D14\" , \"D7\" ), 5 ) # show the phenotypic data pData ( fcs_data ) # save flowSet for next exercise save ( fcs_data , file = \"course_datasets/FR_FCM_Z3WR/fcs_data.RData\" ) #4) Convert the channel names in the expression matrices to the corresponding # antigen names (where applicable) colnames ( fcs_data )[ ! is.na ( antigen )] <- antigen [ ! is.na ( antigen )] # check that the antigen name change was effective: head ( exprs ( fcs_data [[ 1 ]])[, c ( 5 : 10 )]) # 5) Create a bivariate density plot showing \"FSC-H\" against \"HLA-DR\" for all samples from day 0. # Apply a flowJO inverse hyperbolic sine scale to the y axis (\"HLA-DR\") # split by time point fcs_data.split <- split ( fcs_data , pData ( fcs_data ) $ time_point ) class ( fcs_data.split ) # list class ( fcs_data.split $ D0 ) # flowSet # create the bivariate density plot ggcyto :: autoplot ( fcs_data.split $ D0 , x = \"FSC-H\" , y = \"HLA-DR\" , bins = 64 ) + ggcyto :: scale_x_flowjo_biexp () + ggcyto :: scale_y_flowjo_fasinh () # FSC-H = forward scatter height # FSC-A = forward scatter area # SSC-H = side scatter height # SSC-A = side scatter area Let\u2019s practice - 2 We will use the flowSet created in the previous exercise, and transform the data using two sets of cofactors: fixed and estimated using a function from the flowVS package. Create a new script in which you will: 1) Load the flowSet object saved at the end of the previous exercise. 2) Read the \u00abcourse_datasets/FR_FCM_Z3WR/panel.csv\u00bb file into a data frame. The last column contains the marker classes (\u00abnone\u00bb, \u00abtype\u00bb or \u00abstate\u00bb). 3) Downsample the flowSet to 2\u2019000 cells per flowFrame (you can find the downsampling function in the \u00abcourse_datasets/function_for_downsampling_flowSets.R\u00bb file). 4) Transform the \u00abtype\u00bb and \u00abstate\u00bb markers using both Logicle (hints: use the downsampled flowSet for parameter estimation; start with default parameters, and adjust if needed) and arcsinh transformations (fixed cofactors of 3000). 5) Compare the transformation in the first flowFrame using density plots. Answer # load the libraries library ( flowCore ) library ( flowVS ) library ( flowViz ) # 1) load the flowSet object from previous exercise load ( \"course_datasets/FR_FCM_Z3WR/fcs_data.RData\" ) # 2) Add marker_class to panel # load panel from previous exercise panel <- read.csv ( \"course_datasets/FR_FCM_Z3WR/panel.csv\" ) # Set the marker classes panel $ marker_class <- rep ( \"none\" , nrow ( panel )) panel $ marker_class [ c ( 7 : 10 , 11 : 15 , 17 : 18 , 20 , 21 , 23 : 29 , 31 : 36 , 38 , 41 , 42 )] <- \"state\" panel $ marker_class [ c ( 16 , 19 , 22 , 37 , 39 , 40 )] <- \"type\" panel $ marker_class <- factor ( panel $ marker_class , levels = c ( \"type\" , \"state\" , \"none\" )) # write new panel to csv file write.csv ( panel , file = \"course_datasets/FR_FCM_Z3WR/panel_with_marker_classes.csv\" , quote = FALSE , row.names = FALSE ) # View the panel panel #3) Downsample the flowSet to 2'000 cells per flowFrame for parameter estimation # load the function for downsampling a flowset source ( \"course_datasets/function_for_downsampling_flowSets.R\" ) # downsample to 2000 cells fcs_data_small <- Downsampling_flowSet ( x = fcs_data , samplesize = 2000 ) #4) Transform using Logicle and Arcsinh transformation (fixed cofactors) # select markers to be transformed markerstotransform <- panel $ channels [ panel $ marker_class != \"none\" ] # transform with Logicle fcs_list <- list () for ( i in 1 : length ( fcs_data )){ algcl <- estimateLogicle ( fcs_data_small [[ i ]], channels = markerstotransform , m = 6 , t = 4E6 ) fcs_list [[ i ]] <- transform ( fcs_data [[ i ]], algcl ) } fcs_transform_logicle <- as ( fcs_list , \"flowSet\" ) sampleNames ( fcs_transform_logicle ) <- sampleNames ( fcs_data ) pData ( fcs_transform_logicle ) <- pData ( fcs_data ) # transform with fixed cofactors fcs_transform_arcsinh <- transFlowVS ( fcs_data , channels = markerstotransform , rep ( 3000 , length ( markerstotransform ))) sampleNames ( fcs_transform_arcsinh ) <- sampleNames ( fcs_data ) pData ( fcs_transform_arcsinh ) <- pData ( fcs_data ) # 5) Density plots densityplot ( ~ . , fcs_transform_logicle [[ 1 ]]) # worst densityplot ( ~ . , fcs_transform_arcsinh [[ 1 ]]) # worst # save save ( fcs_transform_logicle , markerstotransform , file = \"course_datasets/FR_FCM_Z3WR/fcs_transform_logicle.RData\" ) Let\u2019s practice - 3 We will continue with the Logicle transformed flowSet created in the last exercise, and apply the flowAI quality control algorithm to remove low quality cells. Create a new script in which you will: 1) Load the flowSet object from exercice 2 (\u00ab/course_datasets/FR_FCM_Z3WR/fcs_transform_logicle.RData\u00bb). 2) Run the flowAI quality control algorithm. Set the output directory to \u00abcourse_datasets/FR_FCM_Z3WR/flowAI_res\u00bb. 3) Load the \u00abQcmini.txt\u00bb report created by flowAI and view it. 4) Check the html report for sample 1A9B20_0. What happened ? Answer # load libraries library ( flowCore ) library ( flowAI ) # 1) load the flowSet object from previous exercise and load ( \"course_datasets/FR_FCM_Z3WR/fcs_transform_logicle.RData\" ) # 2) Run the flowAI quality control algorith. # Output the results to a\"course_datasets/FR_FCM_Z3WR/flowAI_res/\" fcs_clean <- flow_auto_qc ( fcs_transform_logicle , folder_results = \"course_datasets/FR_FCM_Z3WR/flowAI_res/\" ) # save clean flowSet save ( fcs_clean , file = \"course_datasets/FR_FCM_Z3WR/fcs_clean.RData\" ) # 3) Load and view the report created by flowAI # load QCmini <- read.delim ( \"course_datasets/FR_FCM_Z3WR/flowAI_res/QCmini.txt\" ) # change the names of the columns names ( QCmini ) <- gsub ( \"X..\" , \"% \" , names ( QCmini )) # View QCmini End of Day 1, good job!","title":"Exercises"},{"location":"flowCyt/day1/exercises_d1/#starting-to-work-with-flow-cytometry-data-in-r-packages","text":"One package that provides data structures and basic functions to deal with flow cytometry data is flowCore . flowCore allows to import data contained within a FCS file and store it in a flowFrame object. Data combined from several FCS files are imported and stored in a flowSet object. Packages that provide functions for automatic quality control are flowAI and PeacoQC . For visualization, the package ggcyto provides plotting functions as an interface to ggplot2 plots using flowFrame or flowSet objects. One example is the autoplot() function. Another package available for visualization is flowViz , which includes the densityplot() function.","title":"Starting to work with flow cytometry data in R - packages"},{"location":"flowCyt/day1/exercises_d1/#lets-practice-1","text":"In this exercise we will use a 36-color spectral flow cytometry dataset from a study performed in the context of Covid-19 research. Only a subset from 5 healthy donors will be used. For each healthy donors, there are three time points, as indicated in the FCS file names. Data was downloaded through the Flow Repository database (FR-FCM-Z3WR) . FCS files were pre-gated on live CD3+CD19- T cells in FlowJo. Create a new script in which you will: 1) Import the FCS files (within course_datasets/FR_FCM_Z3WR/) into a flowSet. Do not transform or truncate the values. 2) Create a data frame with the list of channels and corresponding antigens, and view it. Hint: get the antigens from the parameters of one of the flowFrame in the set 3) Add a new column to the phenotypic data with the time point of the sample. View the phenotypic data 4) Convert the channel names in the expression matrices to the corresponding antigen names (where applicable). 5) Create a bivariate density plot showing \u00abFSC-H\u00bb againts \u00abHLA-DR\u00bb for all samples from day 0. Apply a flowJo inverse hyperbolic sine scale to the y axis (\u00abHLA-DR\u00bb) Answer # load libraries library ( flowCore ) library ( ggcyto ) # 1) Import the FCS files (course_datasets/FR_FCM_Z3WR/). # Do not transform or truncate the values. # path to the directory (folder) with the fcs files fcs.dir <- file.path ( \"course_datasets/FR_FCM_Z3WR/\" ) # read fcs files into a flowSet fcs_data <- flowCore :: read.flowSet ( path = fcs.dir , pattern = \"*.fcs\" , transformation = FALSE , truncate_max_range = FALSE ) # Explore the object: fcs_data summary ( fcs_data [[ 1 ]]) #2) Create a data frame with the list of channels and corresponding antigens, and show it. #Hint: get the antigens from the parameters of one of the flowFrame in the set channels <- colnames ( fcs_data ) antigen <- pData ( parameters ( fcs_data [[ 1 ]])) $ desc panel <- data.frame ( channels = channels , antigen = antigen ) # show the panel panel # write panel to csv file write.csv ( panel , file = \"course_datasets/FR_FCM_Z3WR/panel.csv\" , quote = FALSE , row.names = FALSE ) #3) Add a new column to the phenotypic data with the time point of the sample # check sample names sampleNames ( fcs_data ) # [1] \"0E1F8E_0.fcs\" \"0E1F8E_14.fcs\" \"0E1F8E_7.fcs\" \"180E1A_0.fcs\" \"180E1A_14.fcs\" \"180E1A_7.fcs\" # [7] \"1A9B20_0.fcs\" \"1A9B20_14.fcs\" \"1A9B20_7.fcs\" \"61BBAD_0.fcs\" \"61BBAD_14.fcs\" \"61BBAD_7.fcs\" # [13] \"61BBAD_0.fcs\" \"61BBAD_14.fcs\" \"61BBAD_7.fcs\" # add column with time point pData ( fcs_data ) $ time_point <- rep ( c ( \"D0\" , \"D14\" , \"D7\" ), 5 ) # show the phenotypic data pData ( fcs_data ) # save flowSet for next exercise save ( fcs_data , file = \"course_datasets/FR_FCM_Z3WR/fcs_data.RData\" ) #4) Convert the channel names in the expression matrices to the corresponding # antigen names (where applicable) colnames ( fcs_data )[ ! is.na ( antigen )] <- antigen [ ! is.na ( antigen )] # check that the antigen name change was effective: head ( exprs ( fcs_data [[ 1 ]])[, c ( 5 : 10 )]) # 5) Create a bivariate density plot showing \"FSC-H\" against \"HLA-DR\" for all samples from day 0. # Apply a flowJO inverse hyperbolic sine scale to the y axis (\"HLA-DR\") # split by time point fcs_data.split <- split ( fcs_data , pData ( fcs_data ) $ time_point ) class ( fcs_data.split ) # list class ( fcs_data.split $ D0 ) # flowSet # create the bivariate density plot ggcyto :: autoplot ( fcs_data.split $ D0 , x = \"FSC-H\" , y = \"HLA-DR\" , bins = 64 ) + ggcyto :: scale_x_flowjo_biexp () + ggcyto :: scale_y_flowjo_fasinh () # FSC-H = forward scatter height # FSC-A = forward scatter area # SSC-H = side scatter height # SSC-A = side scatter area","title":"Let's practice - 1"},{"location":"flowCyt/day1/exercises_d1/#lets-practice-2","text":"We will use the flowSet created in the previous exercise, and transform the data using two sets of cofactors: fixed and estimated using a function from the flowVS package. Create a new script in which you will: 1) Load the flowSet object saved at the end of the previous exercise. 2) Read the \u00abcourse_datasets/FR_FCM_Z3WR/panel.csv\u00bb file into a data frame. The last column contains the marker classes (\u00abnone\u00bb, \u00abtype\u00bb or \u00abstate\u00bb). 3) Downsample the flowSet to 2\u2019000 cells per flowFrame (you can find the downsampling function in the \u00abcourse_datasets/function_for_downsampling_flowSets.R\u00bb file). 4) Transform the \u00abtype\u00bb and \u00abstate\u00bb markers using both Logicle (hints: use the downsampled flowSet for parameter estimation; start with default parameters, and adjust if needed) and arcsinh transformations (fixed cofactors of 3000). 5) Compare the transformation in the first flowFrame using density plots. Answer # load the libraries library ( flowCore ) library ( flowVS ) library ( flowViz ) # 1) load the flowSet object from previous exercise load ( \"course_datasets/FR_FCM_Z3WR/fcs_data.RData\" ) # 2) Add marker_class to panel # load panel from previous exercise panel <- read.csv ( \"course_datasets/FR_FCM_Z3WR/panel.csv\" ) # Set the marker classes panel $ marker_class <- rep ( \"none\" , nrow ( panel )) panel $ marker_class [ c ( 7 : 10 , 11 : 15 , 17 : 18 , 20 , 21 , 23 : 29 , 31 : 36 , 38 , 41 , 42 )] <- \"state\" panel $ marker_class [ c ( 16 , 19 , 22 , 37 , 39 , 40 )] <- \"type\" panel $ marker_class <- factor ( panel $ marker_class , levels = c ( \"type\" , \"state\" , \"none\" )) # write new panel to csv file write.csv ( panel , file = \"course_datasets/FR_FCM_Z3WR/panel_with_marker_classes.csv\" , quote = FALSE , row.names = FALSE ) # View the panel panel #3) Downsample the flowSet to 2'000 cells per flowFrame for parameter estimation # load the function for downsampling a flowset source ( \"course_datasets/function_for_downsampling_flowSets.R\" ) # downsample to 2000 cells fcs_data_small <- Downsampling_flowSet ( x = fcs_data , samplesize = 2000 ) #4) Transform using Logicle and Arcsinh transformation (fixed cofactors) # select markers to be transformed markerstotransform <- panel $ channels [ panel $ marker_class != \"none\" ] # transform with Logicle fcs_list <- list () for ( i in 1 : length ( fcs_data )){ algcl <- estimateLogicle ( fcs_data_small [[ i ]], channels = markerstotransform , m = 6 , t = 4E6 ) fcs_list [[ i ]] <- transform ( fcs_data [[ i ]], algcl ) } fcs_transform_logicle <- as ( fcs_list , \"flowSet\" ) sampleNames ( fcs_transform_logicle ) <- sampleNames ( fcs_data ) pData ( fcs_transform_logicle ) <- pData ( fcs_data ) # transform with fixed cofactors fcs_transform_arcsinh <- transFlowVS ( fcs_data , channels = markerstotransform , rep ( 3000 , length ( markerstotransform ))) sampleNames ( fcs_transform_arcsinh ) <- sampleNames ( fcs_data ) pData ( fcs_transform_arcsinh ) <- pData ( fcs_data ) # 5) Density plots densityplot ( ~ . , fcs_transform_logicle [[ 1 ]]) # worst densityplot ( ~ . , fcs_transform_arcsinh [[ 1 ]]) # worst # save save ( fcs_transform_logicle , markerstotransform , file = \"course_datasets/FR_FCM_Z3WR/fcs_transform_logicle.RData\" )","title":"Let's practice - 2"},{"location":"flowCyt/day1/exercises_d1/#lets-practice-3","text":"We will continue with the Logicle transformed flowSet created in the last exercise, and apply the flowAI quality control algorithm to remove low quality cells. Create a new script in which you will: 1) Load the flowSet object from exercice 2 (\u00ab/course_datasets/FR_FCM_Z3WR/fcs_transform_logicle.RData\u00bb). 2) Run the flowAI quality control algorithm. Set the output directory to \u00abcourse_datasets/FR_FCM_Z3WR/flowAI_res\u00bb. 3) Load the \u00abQcmini.txt\u00bb report created by flowAI and view it. 4) Check the html report for sample 1A9B20_0. What happened ? Answer # load libraries library ( flowCore ) library ( flowAI ) # 1) load the flowSet object from previous exercise and load ( \"course_datasets/FR_FCM_Z3WR/fcs_transform_logicle.RData\" ) # 2) Run the flowAI quality control algorith. # Output the results to a\"course_datasets/FR_FCM_Z3WR/flowAI_res/\" fcs_clean <- flow_auto_qc ( fcs_transform_logicle , folder_results = \"course_datasets/FR_FCM_Z3WR/flowAI_res/\" ) # save clean flowSet save ( fcs_clean , file = \"course_datasets/FR_FCM_Z3WR/fcs_clean.RData\" ) # 3) Load and view the report created by flowAI # load QCmini <- read.delim ( \"course_datasets/FR_FCM_Z3WR/flowAI_res/QCmini.txt\" ) # change the names of the columns names ( QCmini ) <- gsub ( \"X..\" , \"% \" , names ( QCmini )) # View QCmini End of Day 1, good job!","title":"Let's practice - 3"},{"location":"flowCyt/day2/exercises_d2/","text":"In this section, you will find the R code that we will use during the course. We will explain the code and output during correction of the exercises. Dimensionality reduction, clustering and differential testing - packages CATALYST provides functions for preprocessing of cytometry data such as FACS, CyTOF, and IMC, as well as functions for dimensional reduction, clustering and methods for differential composition and expression analysis. The CATALYST package provides a function to first cluster data with FlowSOM clustering and then apply ConsensusClusterPlus metaclustering. CATALYST requires the data be contained within an object of class SingleCellExperiment of Bioconductor. An R implementation of the Uniform Manifold Approximation and Projection (UMAP) method for dimensionality reduction is available in the CRAN package uwot . The diffcyt package provides statistical methods for differential discovery analyses in high-dimensional cytometry data (including flow cytometry and mass cytometry). Let\u2019s practice - 4 n this exercise we will continue with the clean flowSet from the last exercise. We will use the CATALYST package to create a SingleCellExperiment (sce) object, perform dimensionality reduction (UMAP) and use the UMAP to plot the expression of markers. Create a new script in which you will: 1) Load the clean flowSet from last exercise (\u00abfcs_clean.Rdata\u00bb). 2) Downsample the flowSet to 2\u2019000 cells per flowFrame (source the file \u00abfunction_for_downsampling_flowSets.R\u00bb) 3) Create a sce object from the downsampled flowSet. 4) Create a UMAP with default parameters, based on the expression of the \u00abtype\u00bb markers. Show the expression of CD3 by time point. 5) Check the effect of changing parameters \u00abmin_dist\u00bb and \u00abn_neighbors\u00bb from the default values. Answer # load libraries library ( flowCore ) library ( CATALYST ) # 1) load the flowSet object from previous exercise load ( \"course_datasets/FR_FCM_Z3WR/fcs_clean.RData\" ) fcs_clean # 2) Downsample to 2'000 cells # source downsampling function source ( \"course_datasets/function_for_downsampling_flowSets.R\" ) # downsample set.seed ( 1234 ) fcs_small <- Downsampling_flowSet ( fcs_clean , samplesize = 2000 ) # 3) Create a sce object from the downsampled flowSet # We need the panel data frame panel <- read.csv ( \"course_datasets/FR_FCM_Z3WR/panel_with_marker_classes.csv\" ) # We also need a metadata dataframe md <- pData ( fcs_small ) # create sce sce <- CATALYST :: prepData ( fcs_small , md = md , md_cols = list ( file = \"name\" , id = \"name\" , factors = \"time_point\" ), panel = panel , panel_cols = list ( channel = \"channels\" , antigen = \"antigen\" , class = \"marker_class\" ), transform = FALSE , FACS = TRUE , features = panel $ channels [ panel $ marker_class != \"none\" ]) # Overview of the object: sce # change the assay name to \"exprs\" because it was already transformed assayNames ( sce ) <- \"exprs\" head ( assays ( sce ) $ exprs [, 1 : 10 ]) # Phenotypic data colData ( sce ) # Channel parameters rowData ( sce ) # save save ( sce , file = \"course_datasets/FR_FCM_Z3WR/sce.RData\" ) # 4) UMAP with default parameters (n_neighbors=15 and min_dist = 0.01) set.seed ( 1601 ) sce <- runDR ( sce , assay = \"exprs\" , dr = \"UMAP\" , features = \"type\" , cells = NULL ) # plot plotDR ( sce , dr = \"UMAP\" , assay = \"exprs\" , color_by = \"CD3\" , facet_by = \"time_point\" ) reducedDims ( sce ) # List of length 1 # names(1): UMAP # save save ( sce , file = \"course_datasets/FR_FCM_Z3WR/sce_UMAP.RData\" ) # 4) UMAP with n_neighbors=15 (defaults) and min_dist = 0.5 set.seed ( 1601 ) sce <- runDR ( sce , assay = \"exprs\" , dr = \"UMAP\" , features = \"type\" , cells = NULL , min_dist = 0.5 ) # the previous UMAP coordinates are overwritten, we still have only 1 reducedDims element: reducedDims ( sce ) # plot plotDR ( sce , dr = \"UMAP\" , assay = \"exprs\" , color_by = \"CD3\" , facet_by = \"time_point\" ) # 4) UMAP with n_neighbors=5 and min_dist = 0.01 (default) set.seed ( 1601 ) sce <- runDR ( sce , assay = \"exprs\" , dr = \"UMAP\" , features = \"type\" , cells = NULL , n_neighbors = 5 ) # plot plotDR ( sce , dr = \"UMAP\" , assay = \"exprs\" , color_by = \"CD3\" , facet_by = \"time_point\" ) # 5) UMAP with n_neighbors=2 and min_dist = 0.5 set.seed ( 1601 ) sce <- runDR ( sce , assay = \"exprs\" , dr = \"UMAP\" , features = \"type\" , cells = NULL , n_neighbors = 2 , min_dist = 0.5 ) # plot plotDR ( sce , dr = \"UMAP\" , assay = \"exprs\" , color_by = \"CD3\" , facet_by = \"time_point\" ) # Try tSNE! It is slower than UMAP if ( TRUE ) { # change this to FALSE after running it so you can just quickly # load the object with TSNE afterwards and save time set.seed ( 1601 ) sce <- runDR ( sce , assay = \"exprs\" , dr = \"TSNE\" , features = \"type\" , cells = NULL ) reducedDims ( sce ) # List of length 2 # names(2): UMAP TSNE save ( sce , file = \"course_datasets/FR_FCM_Z3WR/sce_TSNE.RData\" ) } else { load ( \"course_datasets/FR_FCM_Z3WR/sce_TSNE.RData\" ) reducedDims ( sce ) # List of length 2 # names(2): UMAP TSNE } # plot plotDR ( sce , dr = \"TSNE\" , color_by = \"sample_id\" , facet_by = \"time_point\" ) + ggtitle ( \"TSNE\" ) # Try PCA, using all features and a max number of components table ( rowData ( sce ) $ marker_class ) sce <- runDR ( sce , dr = \"PCA\" , features = NULL , ncomponents = 15 ) reducedDims ( sce ) # List of length 3 # names(3): UMAP TSNE PCA plotDR ( sce , dr = \"PCA\" , color_by = \"time_point\" ) plotDR ( sce , dr = \"PCA\" , color_by = \"CD3\" , facet_by = \"time_point\" ) # ElbowPlot of the top 15 components, could be used as input for # the runDR function with dr = \"UMAP\" and pca = 10. pcs <- SingleCellExperiment :: reducedDim ( x = sce , type = \"PCA\" ) variance <- apply ( X = pcs , MARGIN = 2 , FUN = var ) plot ( x = 1 : 15 , y = variance , xlab = \"Principal components\" , ylab = \"Variance\" ) Let\u2019s practice - 5 In this exercise we will apply the FlowSom method for unsupervised clustering of cells, followed by ConsensusClusterPlus metaclustering. We then check the expression of markers by metacluster. Finally, we will rename / merge the metaclusters to annotate major cell populations. Create a new script in which you will: 1) Load the sce object with UMAP from the previous exercise (\u201ccourse_datasets/FR_FCM_Z3WR/sce_UMAP.RData\u201d). 2) Apply FlowSOM clustering + ConsensusClusterPlus metaclustering. 3) Plot a UMAP showing the location of metaclusters; marker expression heatmap and ridge plots. Use 8 metaclusters. 4) Rename / merge metaclusters as major cell populations according to the expression of markers. 5) Plot a UMAP showing the major cell populations. Answer # load libraries library ( flowCore ) library ( CATALYST ) # 1) Load the sce object with UMAP from previous exercise load ( \"course_datasets/FR_FCM_Z3WR/sce_UMAP.RData\" ) # 2) Apply FlowSOM clustering + ConsensusClusterPlus metaclustering set.seed ( 1234 ) sce <- cluster ( sce , features = \"type\" ) names ( cluster_codes ( sce )) # [1] \"som100\" \"meta2\" \"meta3\" \"meta4\" \"meta5\" \"meta6\" \"meta7\" \"meta8\" \"meta9\" \"meta10\" # [11] \"meta11\" \"meta12\" \"meta13\" \"meta14\" \"meta15\" \"meta16\" \"meta17\" \"meta18\" \"meta19\" \"meta20\" # Plot which shows the change in area under the Consensus Cumulative Distribution function (CDF) per k sce @ metadata $ delta_area # Based on this plot, after k=8, there is not much change anymore. # We could select a k between 5 and 8. # 3) Plot UMAP with clusters, expression heatmap and ridge plots # UMAP plotDR ( sce , dr = \"UMAP\" , color_by = \"meta8\" ) # Heatmap plotExprHeatmap ( sce , row_clust = F , col_clust = F , features = \"type\" , by = \"cluster_id\" , k = \"meta8\" ) # Ridge plots plotClusterExprs ( sce , k = \"meta10\" ) # 4) Rename / merge clusters # create a merging table merging_table <- data.frame ( old_cluster = 1 : 8 , new_cluster = c ( \"CD4 T cells\" , \"Other\" , \"Monocytes\" , \"Other\" , \"CD8 T cells\" , \"CD8 T cells\" , \"Other\" , \"B cells\" )) # write to file write.csv ( merging_table , file = \"course_datasets/FR_FCM_Z3WR/merging_table.csv\" , quote = F , row.names = F ) # annotate clusters sce <- mergeClusters ( sce , k = \"meta8\" , table = merging_table , id = \"Major_cell_populations\" ) # 5) UMAP with major cell populations plotDR ( sce , dr = \"UMAP\" , color_by = \"Major_cell_populations\" ) # Heatmap of antigen (of marker class==\"type\") scaled expression per Major cell population plotExprHeatmap ( sce , row_clust = F , col_clust = F , features = \"type\" , by = \"cluster_id\" , k = \"Major_cell_populations\" ) # save save ( sce , file = \"course_datasets/FR_FCM_Z3WR/sce_annotated.RData\" ) Let\u2019s practice - 6 In this exercise we will test if cell populations have significantly different abundances between two time points (D14 compared to D0). Create a new script in which you will: 1) Load the sce object from the previous exercise (\u201csce_annotated.RData\u201d). 2) Plot relative cell population abundances by sample and time point. 3) Set up the design and contrast matrices. 4) Test for differences in abundances between D14 and D0. 5) View table of results Answer # load libraries library ( CATALYST ) library ( diffcyt ) # 1) Load the sce object with annotation from previous exercise load ( \"course_datasets/FR_FCM_Z3WR/sce_annotated.RData\" ) # 2) Plot relative population abundances by sample, grouped by time point sce $ time_point <- factor ( sce $ time_point , levels = c ( \"D0\" , \"D7\" , \"D14\" )) # stacked bar plot plotAbundances ( sce , k = \"Major_cell_populations\" , by = \"sample_id\" , group_by = \"time_point\" ) # 3) Set up designand contrast matrices. # Set design matrix design <- createDesignMatrix ( ei ( sce ), cols_design = c ( \"time_point\" )) # check design # Set contrast matrix (D14 vs D0) contrast <- createContrast ( c ( 0 , 0 , 1 )) # 4) Compute differential abundance and show top differentially abundant cell populations # compute DA res_DA <- diffcyt ( sce , clustering_to_use = \"Major_cell_populations\" , analysis_type = \"DA\" , method_DA = \"diffcyt-DA-edgeR\" , design = design , contrast = contrast ) # show top differentially abundant cell populations tbl_DA <- rowData ( res_DA $ res ) tbl_DA topTable ( res_DA , format_vals = T ) Let\u2019s practice - 7 In this exercise we will test if markers were differentially expressed between two time points (D14 compared to D0). Create a new script in which you will: 1) Load the sce object from the previous exercise (\u201csce_annotated.RData\u201d). 2) Set up the design and contrast matrices. 3) Test for differences in marker expression between D14 and D0. 4) View table of results. Answer # load libraries library ( CATALYST ) library ( diffcyt ) # 1) Load the sce object with annotation from previous exercise load ( \"course_datasets/FR_FCM_Z3WR/sce_annotated.RData\" ) # 2) Set up design and contrast matrices (D14 vs D0) design <- createDesignMatrix ( ei ( sce ), cols_design = c ( \"time_point\" )) contrast <- createContrast ( c ( 0 , 0 , 1 )) # 3) Compute differential state expression res_DS <- diffcyt ( sce , clustering_to_use = \"Major_cell_populations\" , analysis_type = \"DS\" , method_DS = \"diffcyt-DS-limma\" , design = design , contrast = contrast ) # Are there any differentially expressed markers ? topTable ( res_DS ) # Below is an example of performing a paired analysis, using block_id as a blocking factor: # Adding a covariate such as patient id to perform paired analysis: ? diffcyt # method_DS = c(\"diffcyt-DS-limma\", \"diffcyt-DS-LMM\"), ? testDS_limma # we can use the block_id argument which has to be a vector of patient IDs # create a vector of patient IDs for block design: patient_id <- ei ( sce ) $ sample_id patient_id <- gsub ( \"_0.fcs\" , \"\" , patient_id ) patient_id <- gsub ( \"_14.fcs\" , \"\" , patient_id ) patient_id <- gsub ( \"_7.fcs\" , \"\" , patient_id ) head ( patient_id ) # [1] \"0BF51C\" \"0BF51C\" \"0BF51C\" \"0E1F8E\" \"0E1F8E\" \"0E1F8E\" # 2) Set up design and contrast matrices design <- createDesignMatrix ( ei ( sce ), cols_design = c ( \"time_point\" )) contrast <- createContrast ( c ( 0 , 0 , 1 )) # 3) Compute differential state expression using a vector of patient IDs as block_id argument: res_DS_paired <- diffcyt ( sce , clustering_to_use = \"Major_cell_populations\" , analysis_type = \"DS\" , method_DS = \"diffcyt-DS-limma\" , design = design , contrast = contrast , block_id = patient_id ) # Are there any differentially expressed markers ? # p-values are lower than with the un-paired analysis above topTable ( res_DS_paired ) # Heatmap with time points re-ordered: colData ( sce ) $ sample_id <- factor ( colData ( sce ) $ sample_id , levels = c ( ei ( sce ) $ sample_id [ grep ( \"_0\" , ei ( sce ) $ sample_id )], ei ( sce ) $ sample_id [ grep ( \"_7\" , ei ( sce ) $ sample_id )], ei ( sce ) $ sample_id [ grep ( \"_14\" , ei ( sce ) $ sample_id )])) plotDiffHeatmap ( sce , rowData ( res_DS_paired $ res ), all = T , sort_by = \"lfc\" , col_anno = \"time_point\" ) End of Day 2, good job!","title":"Exercises"},{"location":"flowCyt/day2/exercises_d2/#dimensionality-reduction-clustering-and-differential-testing-packages","text":"CATALYST provides functions for preprocessing of cytometry data such as FACS, CyTOF, and IMC, as well as functions for dimensional reduction, clustering and methods for differential composition and expression analysis. The CATALYST package provides a function to first cluster data with FlowSOM clustering and then apply ConsensusClusterPlus metaclustering. CATALYST requires the data be contained within an object of class SingleCellExperiment of Bioconductor. An R implementation of the Uniform Manifold Approximation and Projection (UMAP) method for dimensionality reduction is available in the CRAN package uwot . The diffcyt package provides statistical methods for differential discovery analyses in high-dimensional cytometry data (including flow cytometry and mass cytometry).","title":"Dimensionality reduction, clustering and differential testing - packages"},{"location":"flowCyt/day2/exercises_d2/#lets-practice-4","text":"n this exercise we will continue with the clean flowSet from the last exercise. We will use the CATALYST package to create a SingleCellExperiment (sce) object, perform dimensionality reduction (UMAP) and use the UMAP to plot the expression of markers. Create a new script in which you will: 1) Load the clean flowSet from last exercise (\u00abfcs_clean.Rdata\u00bb). 2) Downsample the flowSet to 2\u2019000 cells per flowFrame (source the file \u00abfunction_for_downsampling_flowSets.R\u00bb) 3) Create a sce object from the downsampled flowSet. 4) Create a UMAP with default parameters, based on the expression of the \u00abtype\u00bb markers. Show the expression of CD3 by time point. 5) Check the effect of changing parameters \u00abmin_dist\u00bb and \u00abn_neighbors\u00bb from the default values. Answer # load libraries library ( flowCore ) library ( CATALYST ) # 1) load the flowSet object from previous exercise load ( \"course_datasets/FR_FCM_Z3WR/fcs_clean.RData\" ) fcs_clean # 2) Downsample to 2'000 cells # source downsampling function source ( \"course_datasets/function_for_downsampling_flowSets.R\" ) # downsample set.seed ( 1234 ) fcs_small <- Downsampling_flowSet ( fcs_clean , samplesize = 2000 ) # 3) Create a sce object from the downsampled flowSet # We need the panel data frame panel <- read.csv ( \"course_datasets/FR_FCM_Z3WR/panel_with_marker_classes.csv\" ) # We also need a metadata dataframe md <- pData ( fcs_small ) # create sce sce <- CATALYST :: prepData ( fcs_small , md = md , md_cols = list ( file = \"name\" , id = \"name\" , factors = \"time_point\" ), panel = panel , panel_cols = list ( channel = \"channels\" , antigen = \"antigen\" , class = \"marker_class\" ), transform = FALSE , FACS = TRUE , features = panel $ channels [ panel $ marker_class != \"none\" ]) # Overview of the object: sce # change the assay name to \"exprs\" because it was already transformed assayNames ( sce ) <- \"exprs\" head ( assays ( sce ) $ exprs [, 1 : 10 ]) # Phenotypic data colData ( sce ) # Channel parameters rowData ( sce ) # save save ( sce , file = \"course_datasets/FR_FCM_Z3WR/sce.RData\" ) # 4) UMAP with default parameters (n_neighbors=15 and min_dist = 0.01) set.seed ( 1601 ) sce <- runDR ( sce , assay = \"exprs\" , dr = \"UMAP\" , features = \"type\" , cells = NULL ) # plot plotDR ( sce , dr = \"UMAP\" , assay = \"exprs\" , color_by = \"CD3\" , facet_by = \"time_point\" ) reducedDims ( sce ) # List of length 1 # names(1): UMAP # save save ( sce , file = \"course_datasets/FR_FCM_Z3WR/sce_UMAP.RData\" ) # 4) UMAP with n_neighbors=15 (defaults) and min_dist = 0.5 set.seed ( 1601 ) sce <- runDR ( sce , assay = \"exprs\" , dr = \"UMAP\" , features = \"type\" , cells = NULL , min_dist = 0.5 ) # the previous UMAP coordinates are overwritten, we still have only 1 reducedDims element: reducedDims ( sce ) # plot plotDR ( sce , dr = \"UMAP\" , assay = \"exprs\" , color_by = \"CD3\" , facet_by = \"time_point\" ) # 4) UMAP with n_neighbors=5 and min_dist = 0.01 (default) set.seed ( 1601 ) sce <- runDR ( sce , assay = \"exprs\" , dr = \"UMAP\" , features = \"type\" , cells = NULL , n_neighbors = 5 ) # plot plotDR ( sce , dr = \"UMAP\" , assay = \"exprs\" , color_by = \"CD3\" , facet_by = \"time_point\" ) # 5) UMAP with n_neighbors=2 and min_dist = 0.5 set.seed ( 1601 ) sce <- runDR ( sce , assay = \"exprs\" , dr = \"UMAP\" , features = \"type\" , cells = NULL , n_neighbors = 2 , min_dist = 0.5 ) # plot plotDR ( sce , dr = \"UMAP\" , assay = \"exprs\" , color_by = \"CD3\" , facet_by = \"time_point\" ) # Try tSNE! It is slower than UMAP if ( TRUE ) { # change this to FALSE after running it so you can just quickly # load the object with TSNE afterwards and save time set.seed ( 1601 ) sce <- runDR ( sce , assay = \"exprs\" , dr = \"TSNE\" , features = \"type\" , cells = NULL ) reducedDims ( sce ) # List of length 2 # names(2): UMAP TSNE save ( sce , file = \"course_datasets/FR_FCM_Z3WR/sce_TSNE.RData\" ) } else { load ( \"course_datasets/FR_FCM_Z3WR/sce_TSNE.RData\" ) reducedDims ( sce ) # List of length 2 # names(2): UMAP TSNE } # plot plotDR ( sce , dr = \"TSNE\" , color_by = \"sample_id\" , facet_by = \"time_point\" ) + ggtitle ( \"TSNE\" ) # Try PCA, using all features and a max number of components table ( rowData ( sce ) $ marker_class ) sce <- runDR ( sce , dr = \"PCA\" , features = NULL , ncomponents = 15 ) reducedDims ( sce ) # List of length 3 # names(3): UMAP TSNE PCA plotDR ( sce , dr = \"PCA\" , color_by = \"time_point\" ) plotDR ( sce , dr = \"PCA\" , color_by = \"CD3\" , facet_by = \"time_point\" ) # ElbowPlot of the top 15 components, could be used as input for # the runDR function with dr = \"UMAP\" and pca = 10. pcs <- SingleCellExperiment :: reducedDim ( x = sce , type = \"PCA\" ) variance <- apply ( X = pcs , MARGIN = 2 , FUN = var ) plot ( x = 1 : 15 , y = variance , xlab = \"Principal components\" , ylab = \"Variance\" )","title":"Let's practice - 4"},{"location":"flowCyt/day2/exercises_d2/#lets-practice-5","text":"In this exercise we will apply the FlowSom method for unsupervised clustering of cells, followed by ConsensusClusterPlus metaclustering. We then check the expression of markers by metacluster. Finally, we will rename / merge the metaclusters to annotate major cell populations. Create a new script in which you will: 1) Load the sce object with UMAP from the previous exercise (\u201ccourse_datasets/FR_FCM_Z3WR/sce_UMAP.RData\u201d). 2) Apply FlowSOM clustering + ConsensusClusterPlus metaclustering. 3) Plot a UMAP showing the location of metaclusters; marker expression heatmap and ridge plots. Use 8 metaclusters. 4) Rename / merge metaclusters as major cell populations according to the expression of markers. 5) Plot a UMAP showing the major cell populations. Answer # load libraries library ( flowCore ) library ( CATALYST ) # 1) Load the sce object with UMAP from previous exercise load ( \"course_datasets/FR_FCM_Z3WR/sce_UMAP.RData\" ) # 2) Apply FlowSOM clustering + ConsensusClusterPlus metaclustering set.seed ( 1234 ) sce <- cluster ( sce , features = \"type\" ) names ( cluster_codes ( sce )) # [1] \"som100\" \"meta2\" \"meta3\" \"meta4\" \"meta5\" \"meta6\" \"meta7\" \"meta8\" \"meta9\" \"meta10\" # [11] \"meta11\" \"meta12\" \"meta13\" \"meta14\" \"meta15\" \"meta16\" \"meta17\" \"meta18\" \"meta19\" \"meta20\" # Plot which shows the change in area under the Consensus Cumulative Distribution function (CDF) per k sce @ metadata $ delta_area # Based on this plot, after k=8, there is not much change anymore. # We could select a k between 5 and 8. # 3) Plot UMAP with clusters, expression heatmap and ridge plots # UMAP plotDR ( sce , dr = \"UMAP\" , color_by = \"meta8\" ) # Heatmap plotExprHeatmap ( sce , row_clust = F , col_clust = F , features = \"type\" , by = \"cluster_id\" , k = \"meta8\" ) # Ridge plots plotClusterExprs ( sce , k = \"meta10\" ) # 4) Rename / merge clusters # create a merging table merging_table <- data.frame ( old_cluster = 1 : 8 , new_cluster = c ( \"CD4 T cells\" , \"Other\" , \"Monocytes\" , \"Other\" , \"CD8 T cells\" , \"CD8 T cells\" , \"Other\" , \"B cells\" )) # write to file write.csv ( merging_table , file = \"course_datasets/FR_FCM_Z3WR/merging_table.csv\" , quote = F , row.names = F ) # annotate clusters sce <- mergeClusters ( sce , k = \"meta8\" , table = merging_table , id = \"Major_cell_populations\" ) # 5) UMAP with major cell populations plotDR ( sce , dr = \"UMAP\" , color_by = \"Major_cell_populations\" ) # Heatmap of antigen (of marker class==\"type\") scaled expression per Major cell population plotExprHeatmap ( sce , row_clust = F , col_clust = F , features = \"type\" , by = \"cluster_id\" , k = \"Major_cell_populations\" ) # save save ( sce , file = \"course_datasets/FR_FCM_Z3WR/sce_annotated.RData\" )","title":"Let's practice - 5"},{"location":"flowCyt/day2/exercises_d2/#lets-practice-6","text":"In this exercise we will test if cell populations have significantly different abundances between two time points (D14 compared to D0). Create a new script in which you will: 1) Load the sce object from the previous exercise (\u201csce_annotated.RData\u201d). 2) Plot relative cell population abundances by sample and time point. 3) Set up the design and contrast matrices. 4) Test for differences in abundances between D14 and D0. 5) View table of results Answer # load libraries library ( CATALYST ) library ( diffcyt ) # 1) Load the sce object with annotation from previous exercise load ( \"course_datasets/FR_FCM_Z3WR/sce_annotated.RData\" ) # 2) Plot relative population abundances by sample, grouped by time point sce $ time_point <- factor ( sce $ time_point , levels = c ( \"D0\" , \"D7\" , \"D14\" )) # stacked bar plot plotAbundances ( sce , k = \"Major_cell_populations\" , by = \"sample_id\" , group_by = \"time_point\" ) # 3) Set up designand contrast matrices. # Set design matrix design <- createDesignMatrix ( ei ( sce ), cols_design = c ( \"time_point\" )) # check design # Set contrast matrix (D14 vs D0) contrast <- createContrast ( c ( 0 , 0 , 1 )) # 4) Compute differential abundance and show top differentially abundant cell populations # compute DA res_DA <- diffcyt ( sce , clustering_to_use = \"Major_cell_populations\" , analysis_type = \"DA\" , method_DA = \"diffcyt-DA-edgeR\" , design = design , contrast = contrast ) # show top differentially abundant cell populations tbl_DA <- rowData ( res_DA $ res ) tbl_DA topTable ( res_DA , format_vals = T )","title":"Let's practice - 6"},{"location":"flowCyt/day2/exercises_d2/#lets-practice-7","text":"In this exercise we will test if markers were differentially expressed between two time points (D14 compared to D0). Create a new script in which you will: 1) Load the sce object from the previous exercise (\u201csce_annotated.RData\u201d). 2) Set up the design and contrast matrices. 3) Test for differences in marker expression between D14 and D0. 4) View table of results. Answer # load libraries library ( CATALYST ) library ( diffcyt ) # 1) Load the sce object with annotation from previous exercise load ( \"course_datasets/FR_FCM_Z3WR/sce_annotated.RData\" ) # 2) Set up design and contrast matrices (D14 vs D0) design <- createDesignMatrix ( ei ( sce ), cols_design = c ( \"time_point\" )) contrast <- createContrast ( c ( 0 , 0 , 1 )) # 3) Compute differential state expression res_DS <- diffcyt ( sce , clustering_to_use = \"Major_cell_populations\" , analysis_type = \"DS\" , method_DS = \"diffcyt-DS-limma\" , design = design , contrast = contrast ) # Are there any differentially expressed markers ? topTable ( res_DS ) # Below is an example of performing a paired analysis, using block_id as a blocking factor: # Adding a covariate such as patient id to perform paired analysis: ? diffcyt # method_DS = c(\"diffcyt-DS-limma\", \"diffcyt-DS-LMM\"), ? testDS_limma # we can use the block_id argument which has to be a vector of patient IDs # create a vector of patient IDs for block design: patient_id <- ei ( sce ) $ sample_id patient_id <- gsub ( \"_0.fcs\" , \"\" , patient_id ) patient_id <- gsub ( \"_14.fcs\" , \"\" , patient_id ) patient_id <- gsub ( \"_7.fcs\" , \"\" , patient_id ) head ( patient_id ) # [1] \"0BF51C\" \"0BF51C\" \"0BF51C\" \"0E1F8E\" \"0E1F8E\" \"0E1F8E\" # 2) Set up design and contrast matrices design <- createDesignMatrix ( ei ( sce ), cols_design = c ( \"time_point\" )) contrast <- createContrast ( c ( 0 , 0 , 1 )) # 3) Compute differential state expression using a vector of patient IDs as block_id argument: res_DS_paired <- diffcyt ( sce , clustering_to_use = \"Major_cell_populations\" , analysis_type = \"DS\" , method_DS = \"diffcyt-DS-limma\" , design = design , contrast = contrast , block_id = patient_id ) # Are there any differentially expressed markers ? # p-values are lower than with the un-paired analysis above topTable ( res_DS_paired ) # Heatmap with time points re-ordered: colData ( sce ) $ sample_id <- factor ( colData ( sce ) $ sample_id , levels = c ( ei ( sce ) $ sample_id [ grep ( \"_0\" , ei ( sce ) $ sample_id )], ei ( sce ) $ sample_id [ grep ( \"_7\" , ei ( sce ) $ sample_id )], ei ( sce ) $ sample_id [ grep ( \"_14\" , ei ( sce ) $ sample_id )])) plotDiffHeatmap ( sce , rowData ( res_DS_paired $ res ), all = T , sort_by = \"lfc\" , col_anno = \"time_point\" ) End of Day 2, good job!","title":"Let's practice - 7"},{"location":"flowCyt/day3/exercises_d3/","text":"In this section, you will find the R code that we will use during the course. We will explain the code and output during correction of the exercises. Normalization, gating - packages CytoNorm is a package that allows to perform batch correction, i.e. normalization of samples when technical replicates of a single and same sample were run on the several batches used to run the experimental samples. flowWorkspace provides the GatingSet class of objects as an efficient data structure to store, query and visualize gated flow data. CytoML uses platform-specific implementations of the GatingML2.0 standard to exchange gated cytometry data. flowClust can be used for automated gating. It can help in identifying cell populations in flow cytometry data. Robust Model-based Clustering of Flow Cytometry Data (Lo et al. 2008) openCyto implements a hierachical gating pipeline for flow cytometry data. flowGate provides interactive cytometry gating in R, based on a shiny app (web application using R). It is especially geared toward wet-lab cytometerists looking to take advantage of R without having a lot of experience. Let\u2019s practice - 8 In this exercise, we will perform normalization using CytoNorm, and estimating quantiles and splines using a technical replicate distributed across batches. The data comes from the FlowRepository accession . 1) Create a flowSet called fcs_data of all samples within the /course_dataset/FR_FCM_Z4KT folder 2) Generate a panel data.frame using colnames(fcs_data) and antigen names extracted with pData(parameters(fcs_data[[1]]))$desc . Create a new column called marker_class that will contain the type of markers: all the ones that are not NA should be labeled as \u201ctype\u201d, except PD-1 which should be labeled as \u201cstate\u201d. Make sure that the antigen \u201cZombie UV\u201d is labeled as \u201cnone\u201d and not as \u201ctype\u201d. Save the panel to an Excel file using write.xlsx2() . 3) Transform the data: extract a vector from the panel data.frame which are the channels to be transformed, which are the ones that are not labeled with \u201cnone\u201d. Perform asinh transformation with a cofactor of 3000 for all channels to be transformed, using transFlowVS() from the flowVS package. 4) Split the flowSet resulting from transformation into a training flowSet containing all flowFrames from the sample \u201cREU271\u201d, and a flowSet with the rest of the flowFrames not corresponding to sample \u201cREU271\u201d. Use the grep() function on the sampleNames of the flowSet. 5) Perform pre-clustering with flowSOM with function prepareFlowSOM() , providing the flowSet with the training flowFrames, the vector of channels to transform, and FlowSOM.params=list(xdim=10, ydim=10, nClus=20, scale=FALSE) . 6) Test the coefficient of variation within clusters with the testCV() function. 7) Import the metadata with the batch label of each sample contained in the excel file md.xlsx , using read.xlsx2() . Create 2 vectors using the column \u201cbatch\u201d in the md.xlsx file. One vector contains the batch labels of the samples that correspond to sample \u201cREU271\u201d, and another vector contains the batch labels of the other samples (i.e. not \u201cREU271\u201d). 8) Estimate quantiles from the training flowSet using CytoNorm.train() . Use FlowSOM.params = list(nCells = 6000, xdim = 10, ydim = 10, nClus = 5, scale = FALSE) . 9) Normalize the rest of the samples using CytoNorm.normalize() , and using outputDir = \"course_datasets/FR_FCM_Z4KT/Normalized\" ; Make sure this is a new folder. 10) Choosing one channel, create a ridge plot of its distribution within samples before normalization (without the training samples), and one for the normalized samples. For this, you need to create a new flowSet with the created \u201cNorm_\u201d fcs files within the newly created output folder. Use the densityplot() function for each flowSet, storing the output in 2 objects, then use the cowplot plot_grid() function to plot one ridge plot above the other. Answer # load libraries library ( flowCore ) library ( CytoNorm ) library ( xlsx ) # package to export and import data within Excel library ( cowplot ) # package with add-on functions for ggplot2 plotting # 1) generate a flowSet with the fcs files from the FR_FCM_Z4KT data # path to the directory (folder) with the fcs files fcs.dir <- file.path ( \"course_datasets/FR_FCM_Z4KT/\" ) # read fcs files into a flowSet fcs_data <- read.flowSet ( path = fcs.dir , pattern = \"*.fcs\" , transformation = FALSE , truncate_max_range = FALSE ) #fcs_data will be a FlowSet object # Check the object: fcs_data # retrieve the list of channels and corresponding antigens fcs_colname <- colnames ( fcs_data ) antigen <- pData ( parameters ( fcs_data [[ 1 ]])) $ desc # setting marker classes. In this panel, only PD-1 is a state marker: marker_class <- rep ( \"none\" , ncol ( fcs_data [[ 1 ]])) # setting all to \"none\" marker_class [ which ( ! is.na ( antigen ))] <- \"type\" # type markers marker_class [ which ( antigen == \"PD-1\" )] <- \"state\" # state markers # change UV marker to \"none\" marker_class [ which ( antigen == \"Zombie UV\" )] <- \"none\" # state markers marker_class <- factor ( marker_class , levels = c ( \"type\" , \"state\" , \"none\" )) # put everything together in a data frame panel <- data.frame ( fcs_colname , antigen , marker_class , row.names = NULL ) # check that the type/none/state column is correct: panel # Export to excel file, which can be read in with read.xlsx2() xlsx :: write.xlsx2 ( panel , file = \"course_datasets/FR_FCM_Z4KT/panel_Z4KT.xlsx\" , sheetName = \"panel_Z4KT\" ) # Import an Excel sheet as a data.frame: # Using sheet index panel <- read.xlsx2 ( \"course_datasets/FR_FCM_Z4KT/panel_Z4KT.xlsx\" , sheetIndex = 1 ) # using sheet name: panel <- read.xlsx2 ( \"course_datasets/FR_FCM_Z4KT/panel_Z4KT.xlsx\" , sheetName = \"panel_Z4KT\" ) ## Arcsinh transformation with a fixed cofactor of 3000 # Select markers to be transformed: markerstotransf <- panel $ fcs_colname [ panel $ marker_class != \"none\" ] # set cofactor vector cofactor <- 3000 l <- length ( markerstotransf ) cofactors <- rep ( cofactor , l ) # transform fcs_transform <- transFlowVS ( fcs_data , channels = markerstotransf , cofactors ) # the output is a flowSet: fcs_transform # save to a file for downstream analysis save ( fcs_transform , file = \"course_datasets/FR_FCM_Z4KT/fcs_transform.RData\" ) # Used transformed data for CytoNorm: # Separate the files according to training and validation set: # sample REU271 was measured on several days: train_files <- fcs_transform [ grep ( \"REU271\" , sampleNames ( fcs_transform ))] validation_files <- fcs_transform [ - c ( grep ( \"REU271\" , sampleNames ( fcs_transform )))] # Pre-clustering with FlowSOM: ? CytoNorm :: prepareFlowSOM fsom <- prepareFlowSOM ( train_files , colsToUse = markerstotransf , transformList = NULL , FlowSOM.params = list ( xdim = 10 , ydim = 10 , nClus = 20 , scale = FALSE )) fsom # Check coefficient of variation within cluster: # Function to inspect whether all control samples contain a # similar percentage of cells in all FlowSOM clusters cvs <- CytoNorm :: testCV ( fsom , cluster_values = c ( 5 , 10 , 15 , 20 )) range ( cvs $ cvs $ `20` ) # 0.05758965 1.43114512 # If the clusters are impacted by batch effects, CV values of >1.5 or 2 will # occur, then you can choose to put FlowSOM.params to NULL # and skip clustering. # Import sample metadata and batch info, which should include Sample_ID # and batch columns: md <- xlsx :: read.xlsx2 ( \"course_datasets/FR_FCM_Z4KT/md.xlsx\" , sheetIndex = 1 ) head ( md ) # Check that the order of fcs files within folder is the same as within the metadata: file_names <- list.files ( fcs.dir , pattern = \".fcs\" ) summary ( md $ file_name == file_names ) # Mode TRUE # logical 16 # extract the batch labels of the training sample: labels_train <- md $ batch [ grep ( \"REU271\" , md $ Sample_ID )] labels_train # [1] \"B\" \"C\" \"D\" \"E\" \"F\" \"A\" model <- CytoNorm.train ( files = train_files , labels = labels_train , channels = markerstotransf , transformList = NULL , FlowSOM.params = list ( nCells = 6000 , xdim = 10 , ydim = 10 , nClus = 5 , scale = FALSE ), normMethod.train = QuantileNorm.train , normParams = list ( nQ = 101 , goal = \"mean\" ), seed = 1 , verbose = TRUE ) # View the quantile values: model $ clusterRes $ `5` # Normalize the rest of the files: label_norm <- md $ batch [ - c ( grep ( \"REU271\" , md $ Sample_ID ))] CytoNorm.normalize ( model = model , files = validation_files , labels = label_norm , transformList = NULL , transformList.reverse = NULL , normMethod.normalize = QuantileNorm.normalize , outputDir = \"course_datasets/FR_FCM_Z4KT/Normalized\" , prefix = \"Norm_\" , clean = TRUE , verbose = TRUE ) fcs.dir <- file.path ( \"course_datasets/FR_FCM_Z4KT/Normalized\" ) fcs_norm <- read.flowSet ( path = fcs.dir , pattern = \"*.fcs\" , transformation = FALSE , truncate_max_range = FALSE ) # Compare the distribution a marker across replicates colnames ( fcs_norm ) # before normalization (without plotting the training samples) p1 <- densityplot ( ~ `FJComp-BUV496-A` , fcs_transform [ - c ( grep ( \"REU271\" , sampleNames ( fcs_transform )))]) # after normalization p2 <- densityplot ( ~ `FJComp-BUV496-A` , fcs_norm ) cowplot :: plot_grid ( p1 , p2 , nrow = 2 ) Let\u2019s practice - 9 In this exercise we will do some gating using flowGate and data from the FR_FCM_Z3WR of the FlowRepository. Create a new script in which you will: 1) Create a flowSet of all samples within the /course_dataset/FR_FCM_Z3WR folder 2) Perform asinh transformation with a cofactor of 3000 for all channels not labeled with \u201cnone\u201d, using transFlowVS() from the flowVS package. Use the csv file with the panel previously created \"/course_datasets/FR_FCM_Z3WR/panel_with_marker_classes.csv\" . 3) Convert the flowSet to a GatingSet 4) Using flowGate, create a gating hierarchy according to the scheme depicted below. Don\u2019t forget to check your gating with scatter or density plots. 5) Do necessary adjustements so that your gating hierarchy looks like the one depicted below. 6) What is the percentage of CD8+ T cells among T cells (\u201cCD3\u201d). Gating hierarchy: Answer # load libraries library ( flowCore ) library ( flowWorkspace ) library ( flowGate ) library ( flowVS ) # 1) Create a flowSet from the FCS files in \"course_datasets/FR_FCM_Z3WR/\" fs <- read.flowSet ( path = \"course_datasets/FR_FCM_Z3WR/\" , pattern = \"*.fcs\" , transformation = FALSE , truncate_max_range = FALSE ) # 2 ) FlowVS Arcsinh transformation with fixed factors (3000). # Use the csv file containing the panel and marker classes previously created # (\"course_datasets/FR_FCM_Z3WR/panel_with_marker_classes.csv\") panel <- read.csv ( \"course_datasets/FR_FCM_Z3WR/panel_with_marker_classes.csv\" ) markerstotransform <- as.character ( panel $ channels )[ ! is.na ( panel $ antigen )] fs <- transFlowVS ( fs , channels = markerstotransform , cofactors = rep ( 3000 , length ( markerstotransform ))) # 3) Convert the flowSet to a GatingSet gs <- GatingSet ( fs ) # save for next exercise #save_gs(gs, path = \"course_datasets/FR_FCM_Z3WR/gs_preprocessed\") # 4) Using flowGate, create the following gates # Polygon gate (\"Leukocytes\") gs_gate_interactive ( gs , filterId = \"Leukocytes\" , dims = list ( \"FSC-H\" , \"SSC-H\" )) autoplot ( gs [[ 1 ]], gate = \"Leukocytes\" ) plot ( gs ) # span gate (\"CD3\") gs_gate_interactive ( gs , filterId = \"CD3\" , dims = \"BV510-A\" , subset = \"Leukocytes\" ) autoplot ( gs [[ 1 ]], gate = \"CD3\" ) plot ( gs ) # quadrant gate (\"CD4 CD8\") # BUV615-A = CD4 # BUV805-A = CD8 gs_gate_interactive ( gs , filterId = \"CD4 CD8\" , dims = list ( \"BUV615-A\" , \"BUV805-A\" ), subset = \"CD3\" ) plot ( gs ) autoplot ( gs [[ 1 ]], gate = gs_pop_get_children ( gs , \"CD3\" )) # 5) Make the necessary adjustements so that the gate tree loks like the one depicted. # Check node names gs_get_pop_paths ( gs , path = 1 ) # Rename the CD4 CD8 gates to CD4+, CD8+, DNT and DPT gs_pop_set_name ( gs , \"BUV615-A-BUV805-A+\" , \"CD8+\" ) gs_pop_set_name ( gs , \"BUV615-A+BUV805-A-\" , \"CD4+\" ) gs_pop_set_name ( gs , \"BUV615-A+BUV805-A+\" , \"DPT\" ) gs_pop_set_name ( gs , \"BUV615-A-BUV805-A-\" , \"DNT\" ) plot ( gs ) # 6) What is the percentage of CD8+ T cells among T cells (\"CD3\") gs_pop_get_stats ( gs , nodes = \"CD8+\" , type = \"percent\" ) Let\u2019s practice - 10 In this exercise we will repeat the gating previously done with flowGate on the data from FR_FCM_Z3WR of the FlowRepository, but this time using automated gating with openCyto. Create a new script in which you will: 1) Repeat steps 1 to 4 from the previous exercise (loading data from fcs files and preprocessing). You can also load the preprocessed GatingSet from /course_dataset/FR_FCM_Z3WR/gs_preprocessed/ . 2) Using the gs_add_gating_method() function (i.e., without a template), create a gating hierarchy according to the scheme depicted below. Don\u2019t forget to check your gating with scatter or density plots. 3) Do necessary adjustements so that your gating hierarchy looks like the one depicted below (hide the \u201cBUV805-A+\u201d and \u201cBUV615-A+\u201d nodes from the tree, and rename the CD4, CD8, DNT and DPT nodes). 4) Create a boxplot showing the percentage of CD8+ T cells among T cells (\u201cCD3\u201d) per patient, as a function of time points. Gating hierarchy: Answer # load libraries library ( flowCore ) library ( flowWorkspace ) library ( openCyto ) library ( ggcyto ) # 1) Repeat steps 1 to 4 from previous exercise (loading data, preprocessing) # load the preprocessed ungated data gs <- load_gs ( \"course_datasets/FR_FCM_Z3WR/gs_preprocessed\" ) # 2) Apply the gating as in the scheme # gate \"Leukocytes\" # use flowClust # set a K=3, to split in three populations and select the one with the highest \"peak\" gs_add_gating_method ( gs , alias = \"Leukocytes\" , parent = \"root\" , dims = \"FSC-H,SSC-H\" , gating_method = \"flowClust\" , gating_args = \"K=3\" ) # check plot ( gs ) autoplot ( gs [[ 1 ]], gate = \"Leukocytes\" ) # gate \"CD3\" # use minDensity gs_add_gating_method ( gs , alias = \"CD3\" , parent = \"Leukocytes\" , dims = \"BV510-A\" , gating_method = \"gate_mindensity\" , pop = \"+\" ) # check plot ( gs ) autoplot ( gs [[ 1 ]], gate = \"CD3\" ) # gate \"CD4 CD8\" # use minDensity gs_add_gating_method ( gs , alias = \"*\" , parent = \"CD3\" , dims = \"BUV615-A,BUV805-A\" , gating_method = \"gate_mindensity\" , pop = \"-/++/-\" ) # check plot ( gs ) gs_pop_get_children ( gs , \"CD3\" ) autoplot ( gs [[ 1 ]], gate = gs_pop_get_children ( gs , \"CD3\" )) autoplot ( gs [[ 1 ]], gate = gs_pop_get_children ( gs , \"CD3\" )[ 3 : 6 ]) # 3) # Hide the \"BUV805-A+\" and \"BUV615-A+\" nodes from the tree gs_pop_set_visibility ( gs , \"BUV805-A+\" , FALSE ) gs_pop_set_visibility ( gs , \"BUV615-A+\" , FALSE ) # check plot ( gs ) # 4) Rename the CD4 CD8 gates to CD4+, CD8+, DNT and DPT # Rename the CD4 CD8 gates to CD4+, CD8+, DNT and DPT gs_pop_set_name ( gs , \"BUV615-A-BUV805-A+\" , \"CD8+\" ) gs_pop_set_name ( gs , \"BUV615-A+BUV805-A-\" , \"CD4+\" ) gs_pop_set_name ( gs , \"BUV615-A+BUV805-A+\" , \"DPT\" ) gs_pop_set_name ( gs , \"BUV615-A-BUV805-A-\" , \"DNT\" ) # check plot ( gs ) # 5) Create a boxplot showing the percentage of CD8+ T cells among T cells (\"CD3\") as a function of time point # extract the proportions my_proportions <- gs_pop_get_stats ( gs , nodes = \"CD8+\" , type = \"percent\" ) # add the timepoints my_proportions $ time_point <- rep ( c ( 0 , 14 , 7 ), 5 ) # convert to factor (order in the plot) my_proportions $ time_point <- factor ( my_proportions $ time_point , levels = c ( 0 , 7 , 14 )) # create the boxplot boxplot ( percent ~ time_point , data = my_proportions ) End of Day 3, good job!","title":"Exercises"},{"location":"flowCyt/day3/exercises_d3/#normalization-gating-packages","text":"CytoNorm is a package that allows to perform batch correction, i.e. normalization of samples when technical replicates of a single and same sample were run on the several batches used to run the experimental samples. flowWorkspace provides the GatingSet class of objects as an efficient data structure to store, query and visualize gated flow data. CytoML uses platform-specific implementations of the GatingML2.0 standard to exchange gated cytometry data. flowClust can be used for automated gating. It can help in identifying cell populations in flow cytometry data. Robust Model-based Clustering of Flow Cytometry Data (Lo et al. 2008) openCyto implements a hierachical gating pipeline for flow cytometry data. flowGate provides interactive cytometry gating in R, based on a shiny app (web application using R). It is especially geared toward wet-lab cytometerists looking to take advantage of R without having a lot of experience.","title":"Normalization, gating - packages"},{"location":"flowCyt/day3/exercises_d3/#lets-practice-8","text":"In this exercise, we will perform normalization using CytoNorm, and estimating quantiles and splines using a technical replicate distributed across batches. The data comes from the FlowRepository accession . 1) Create a flowSet called fcs_data of all samples within the /course_dataset/FR_FCM_Z4KT folder 2) Generate a panel data.frame using colnames(fcs_data) and antigen names extracted with pData(parameters(fcs_data[[1]]))$desc . Create a new column called marker_class that will contain the type of markers: all the ones that are not NA should be labeled as \u201ctype\u201d, except PD-1 which should be labeled as \u201cstate\u201d. Make sure that the antigen \u201cZombie UV\u201d is labeled as \u201cnone\u201d and not as \u201ctype\u201d. Save the panel to an Excel file using write.xlsx2() . 3) Transform the data: extract a vector from the panel data.frame which are the channels to be transformed, which are the ones that are not labeled with \u201cnone\u201d. Perform asinh transformation with a cofactor of 3000 for all channels to be transformed, using transFlowVS() from the flowVS package. 4) Split the flowSet resulting from transformation into a training flowSet containing all flowFrames from the sample \u201cREU271\u201d, and a flowSet with the rest of the flowFrames not corresponding to sample \u201cREU271\u201d. Use the grep() function on the sampleNames of the flowSet. 5) Perform pre-clustering with flowSOM with function prepareFlowSOM() , providing the flowSet with the training flowFrames, the vector of channels to transform, and FlowSOM.params=list(xdim=10, ydim=10, nClus=20, scale=FALSE) . 6) Test the coefficient of variation within clusters with the testCV() function. 7) Import the metadata with the batch label of each sample contained in the excel file md.xlsx , using read.xlsx2() . Create 2 vectors using the column \u201cbatch\u201d in the md.xlsx file. One vector contains the batch labels of the samples that correspond to sample \u201cREU271\u201d, and another vector contains the batch labels of the other samples (i.e. not \u201cREU271\u201d). 8) Estimate quantiles from the training flowSet using CytoNorm.train() . Use FlowSOM.params = list(nCells = 6000, xdim = 10, ydim = 10, nClus = 5, scale = FALSE) . 9) Normalize the rest of the samples using CytoNorm.normalize() , and using outputDir = \"course_datasets/FR_FCM_Z4KT/Normalized\" ; Make sure this is a new folder. 10) Choosing one channel, create a ridge plot of its distribution within samples before normalization (without the training samples), and one for the normalized samples. For this, you need to create a new flowSet with the created \u201cNorm_\u201d fcs files within the newly created output folder. Use the densityplot() function for each flowSet, storing the output in 2 objects, then use the cowplot plot_grid() function to plot one ridge plot above the other. Answer # load libraries library ( flowCore ) library ( CytoNorm ) library ( xlsx ) # package to export and import data within Excel library ( cowplot ) # package with add-on functions for ggplot2 plotting # 1) generate a flowSet with the fcs files from the FR_FCM_Z4KT data # path to the directory (folder) with the fcs files fcs.dir <- file.path ( \"course_datasets/FR_FCM_Z4KT/\" ) # read fcs files into a flowSet fcs_data <- read.flowSet ( path = fcs.dir , pattern = \"*.fcs\" , transformation = FALSE , truncate_max_range = FALSE ) #fcs_data will be a FlowSet object # Check the object: fcs_data # retrieve the list of channels and corresponding antigens fcs_colname <- colnames ( fcs_data ) antigen <- pData ( parameters ( fcs_data [[ 1 ]])) $ desc # setting marker classes. In this panel, only PD-1 is a state marker: marker_class <- rep ( \"none\" , ncol ( fcs_data [[ 1 ]])) # setting all to \"none\" marker_class [ which ( ! is.na ( antigen ))] <- \"type\" # type markers marker_class [ which ( antigen == \"PD-1\" )] <- \"state\" # state markers # change UV marker to \"none\" marker_class [ which ( antigen == \"Zombie UV\" )] <- \"none\" # state markers marker_class <- factor ( marker_class , levels = c ( \"type\" , \"state\" , \"none\" )) # put everything together in a data frame panel <- data.frame ( fcs_colname , antigen , marker_class , row.names = NULL ) # check that the type/none/state column is correct: panel # Export to excel file, which can be read in with read.xlsx2() xlsx :: write.xlsx2 ( panel , file = \"course_datasets/FR_FCM_Z4KT/panel_Z4KT.xlsx\" , sheetName = \"panel_Z4KT\" ) # Import an Excel sheet as a data.frame: # Using sheet index panel <- read.xlsx2 ( \"course_datasets/FR_FCM_Z4KT/panel_Z4KT.xlsx\" , sheetIndex = 1 ) # using sheet name: panel <- read.xlsx2 ( \"course_datasets/FR_FCM_Z4KT/panel_Z4KT.xlsx\" , sheetName = \"panel_Z4KT\" ) ## Arcsinh transformation with a fixed cofactor of 3000 # Select markers to be transformed: markerstotransf <- panel $ fcs_colname [ panel $ marker_class != \"none\" ] # set cofactor vector cofactor <- 3000 l <- length ( markerstotransf ) cofactors <- rep ( cofactor , l ) # transform fcs_transform <- transFlowVS ( fcs_data , channels = markerstotransf , cofactors ) # the output is a flowSet: fcs_transform # save to a file for downstream analysis save ( fcs_transform , file = \"course_datasets/FR_FCM_Z4KT/fcs_transform.RData\" ) # Used transformed data for CytoNorm: # Separate the files according to training and validation set: # sample REU271 was measured on several days: train_files <- fcs_transform [ grep ( \"REU271\" , sampleNames ( fcs_transform ))] validation_files <- fcs_transform [ - c ( grep ( \"REU271\" , sampleNames ( fcs_transform )))] # Pre-clustering with FlowSOM: ? CytoNorm :: prepareFlowSOM fsom <- prepareFlowSOM ( train_files , colsToUse = markerstotransf , transformList = NULL , FlowSOM.params = list ( xdim = 10 , ydim = 10 , nClus = 20 , scale = FALSE )) fsom # Check coefficient of variation within cluster: # Function to inspect whether all control samples contain a # similar percentage of cells in all FlowSOM clusters cvs <- CytoNorm :: testCV ( fsom , cluster_values = c ( 5 , 10 , 15 , 20 )) range ( cvs $ cvs $ `20` ) # 0.05758965 1.43114512 # If the clusters are impacted by batch effects, CV values of >1.5 or 2 will # occur, then you can choose to put FlowSOM.params to NULL # and skip clustering. # Import sample metadata and batch info, which should include Sample_ID # and batch columns: md <- xlsx :: read.xlsx2 ( \"course_datasets/FR_FCM_Z4KT/md.xlsx\" , sheetIndex = 1 ) head ( md ) # Check that the order of fcs files within folder is the same as within the metadata: file_names <- list.files ( fcs.dir , pattern = \".fcs\" ) summary ( md $ file_name == file_names ) # Mode TRUE # logical 16 # extract the batch labels of the training sample: labels_train <- md $ batch [ grep ( \"REU271\" , md $ Sample_ID )] labels_train # [1] \"B\" \"C\" \"D\" \"E\" \"F\" \"A\" model <- CytoNorm.train ( files = train_files , labels = labels_train , channels = markerstotransf , transformList = NULL , FlowSOM.params = list ( nCells = 6000 , xdim = 10 , ydim = 10 , nClus = 5 , scale = FALSE ), normMethod.train = QuantileNorm.train , normParams = list ( nQ = 101 , goal = \"mean\" ), seed = 1 , verbose = TRUE ) # View the quantile values: model $ clusterRes $ `5` # Normalize the rest of the files: label_norm <- md $ batch [ - c ( grep ( \"REU271\" , md $ Sample_ID ))] CytoNorm.normalize ( model = model , files = validation_files , labels = label_norm , transformList = NULL , transformList.reverse = NULL , normMethod.normalize = QuantileNorm.normalize , outputDir = \"course_datasets/FR_FCM_Z4KT/Normalized\" , prefix = \"Norm_\" , clean = TRUE , verbose = TRUE ) fcs.dir <- file.path ( \"course_datasets/FR_FCM_Z4KT/Normalized\" ) fcs_norm <- read.flowSet ( path = fcs.dir , pattern = \"*.fcs\" , transformation = FALSE , truncate_max_range = FALSE ) # Compare the distribution a marker across replicates colnames ( fcs_norm ) # before normalization (without plotting the training samples) p1 <- densityplot ( ~ `FJComp-BUV496-A` , fcs_transform [ - c ( grep ( \"REU271\" , sampleNames ( fcs_transform )))]) # after normalization p2 <- densityplot ( ~ `FJComp-BUV496-A` , fcs_norm ) cowplot :: plot_grid ( p1 , p2 , nrow = 2 )","title":"Let's practice - 8"},{"location":"flowCyt/day3/exercises_d3/#lets-practice-9","text":"In this exercise we will do some gating using flowGate and data from the FR_FCM_Z3WR of the FlowRepository. Create a new script in which you will: 1) Create a flowSet of all samples within the /course_dataset/FR_FCM_Z3WR folder 2) Perform asinh transformation with a cofactor of 3000 for all channels not labeled with \u201cnone\u201d, using transFlowVS() from the flowVS package. Use the csv file with the panel previously created \"/course_datasets/FR_FCM_Z3WR/panel_with_marker_classes.csv\" . 3) Convert the flowSet to a GatingSet 4) Using flowGate, create a gating hierarchy according to the scheme depicted below. Don\u2019t forget to check your gating with scatter or density plots. 5) Do necessary adjustements so that your gating hierarchy looks like the one depicted below. 6) What is the percentage of CD8+ T cells among T cells (\u201cCD3\u201d). Gating hierarchy: Answer # load libraries library ( flowCore ) library ( flowWorkspace ) library ( flowGate ) library ( flowVS ) # 1) Create a flowSet from the FCS files in \"course_datasets/FR_FCM_Z3WR/\" fs <- read.flowSet ( path = \"course_datasets/FR_FCM_Z3WR/\" , pattern = \"*.fcs\" , transformation = FALSE , truncate_max_range = FALSE ) # 2 ) FlowVS Arcsinh transformation with fixed factors (3000). # Use the csv file containing the panel and marker classes previously created # (\"course_datasets/FR_FCM_Z3WR/panel_with_marker_classes.csv\") panel <- read.csv ( \"course_datasets/FR_FCM_Z3WR/panel_with_marker_classes.csv\" ) markerstotransform <- as.character ( panel $ channels )[ ! is.na ( panel $ antigen )] fs <- transFlowVS ( fs , channels = markerstotransform , cofactors = rep ( 3000 , length ( markerstotransform ))) # 3) Convert the flowSet to a GatingSet gs <- GatingSet ( fs ) # save for next exercise #save_gs(gs, path = \"course_datasets/FR_FCM_Z3WR/gs_preprocessed\") # 4) Using flowGate, create the following gates # Polygon gate (\"Leukocytes\") gs_gate_interactive ( gs , filterId = \"Leukocytes\" , dims = list ( \"FSC-H\" , \"SSC-H\" )) autoplot ( gs [[ 1 ]], gate = \"Leukocytes\" ) plot ( gs ) # span gate (\"CD3\") gs_gate_interactive ( gs , filterId = \"CD3\" , dims = \"BV510-A\" , subset = \"Leukocytes\" ) autoplot ( gs [[ 1 ]], gate = \"CD3\" ) plot ( gs ) # quadrant gate (\"CD4 CD8\") # BUV615-A = CD4 # BUV805-A = CD8 gs_gate_interactive ( gs , filterId = \"CD4 CD8\" , dims = list ( \"BUV615-A\" , \"BUV805-A\" ), subset = \"CD3\" ) plot ( gs ) autoplot ( gs [[ 1 ]], gate = gs_pop_get_children ( gs , \"CD3\" )) # 5) Make the necessary adjustements so that the gate tree loks like the one depicted. # Check node names gs_get_pop_paths ( gs , path = 1 ) # Rename the CD4 CD8 gates to CD4+, CD8+, DNT and DPT gs_pop_set_name ( gs , \"BUV615-A-BUV805-A+\" , \"CD8+\" ) gs_pop_set_name ( gs , \"BUV615-A+BUV805-A-\" , \"CD4+\" ) gs_pop_set_name ( gs , \"BUV615-A+BUV805-A+\" , \"DPT\" ) gs_pop_set_name ( gs , \"BUV615-A-BUV805-A-\" , \"DNT\" ) plot ( gs ) # 6) What is the percentage of CD8+ T cells among T cells (\"CD3\") gs_pop_get_stats ( gs , nodes = \"CD8+\" , type = \"percent\" )","title":"Let's practice - 9"},{"location":"flowCyt/day3/exercises_d3/#lets-practice-10","text":"In this exercise we will repeat the gating previously done with flowGate on the data from FR_FCM_Z3WR of the FlowRepository, but this time using automated gating with openCyto. Create a new script in which you will: 1) Repeat steps 1 to 4 from the previous exercise (loading data from fcs files and preprocessing). You can also load the preprocessed GatingSet from /course_dataset/FR_FCM_Z3WR/gs_preprocessed/ . 2) Using the gs_add_gating_method() function (i.e., without a template), create a gating hierarchy according to the scheme depicted below. Don\u2019t forget to check your gating with scatter or density plots. 3) Do necessary adjustements so that your gating hierarchy looks like the one depicted below (hide the \u201cBUV805-A+\u201d and \u201cBUV615-A+\u201d nodes from the tree, and rename the CD4, CD8, DNT and DPT nodes). 4) Create a boxplot showing the percentage of CD8+ T cells among T cells (\u201cCD3\u201d) per patient, as a function of time points. Gating hierarchy: Answer # load libraries library ( flowCore ) library ( flowWorkspace ) library ( openCyto ) library ( ggcyto ) # 1) Repeat steps 1 to 4 from previous exercise (loading data, preprocessing) # load the preprocessed ungated data gs <- load_gs ( \"course_datasets/FR_FCM_Z3WR/gs_preprocessed\" ) # 2) Apply the gating as in the scheme # gate \"Leukocytes\" # use flowClust # set a K=3, to split in three populations and select the one with the highest \"peak\" gs_add_gating_method ( gs , alias = \"Leukocytes\" , parent = \"root\" , dims = \"FSC-H,SSC-H\" , gating_method = \"flowClust\" , gating_args = \"K=3\" ) # check plot ( gs ) autoplot ( gs [[ 1 ]], gate = \"Leukocytes\" ) # gate \"CD3\" # use minDensity gs_add_gating_method ( gs , alias = \"CD3\" , parent = \"Leukocytes\" , dims = \"BV510-A\" , gating_method = \"gate_mindensity\" , pop = \"+\" ) # check plot ( gs ) autoplot ( gs [[ 1 ]], gate = \"CD3\" ) # gate \"CD4 CD8\" # use minDensity gs_add_gating_method ( gs , alias = \"*\" , parent = \"CD3\" , dims = \"BUV615-A,BUV805-A\" , gating_method = \"gate_mindensity\" , pop = \"-/++/-\" ) # check plot ( gs ) gs_pop_get_children ( gs , \"CD3\" ) autoplot ( gs [[ 1 ]], gate = gs_pop_get_children ( gs , \"CD3\" )) autoplot ( gs [[ 1 ]], gate = gs_pop_get_children ( gs , \"CD3\" )[ 3 : 6 ]) # 3) # Hide the \"BUV805-A+\" and \"BUV615-A+\" nodes from the tree gs_pop_set_visibility ( gs , \"BUV805-A+\" , FALSE ) gs_pop_set_visibility ( gs , \"BUV615-A+\" , FALSE ) # check plot ( gs ) # 4) Rename the CD4 CD8 gates to CD4+, CD8+, DNT and DPT # Rename the CD4 CD8 gates to CD4+, CD8+, DNT and DPT gs_pop_set_name ( gs , \"BUV615-A-BUV805-A+\" , \"CD8+\" ) gs_pop_set_name ( gs , \"BUV615-A+BUV805-A-\" , \"CD4+\" ) gs_pop_set_name ( gs , \"BUV615-A+BUV805-A+\" , \"DPT\" ) gs_pop_set_name ( gs , \"BUV615-A-BUV805-A-\" , \"DNT\" ) # check plot ( gs ) # 5) Create a boxplot showing the percentage of CD8+ T cells among T cells (\"CD3\") as a function of time point # extract the proportions my_proportions <- gs_pop_get_stats ( gs , nodes = \"CD8+\" , type = \"percent\" ) # add the timepoints my_proportions $ time_point <- rep ( c ( 0 , 14 , 7 ), 5 ) # convert to factor (order in the plot) my_proportions $ time_point <- factor ( my_proportions $ time_point , levels = c ( 0 , 7 , 14 )) # create the boxplot boxplot ( percent ~ time_point , data = my_proportions ) End of Day 3, good job!","title":"Let's practice - 10"},{"location":"flowCyt/day4/exercises_d4/","text":"In this section, you will find the R code that we will use during the course. We will explain the code and output during correction of the exercises. Reporting - R Markdown If a data analysis project involves many steps and generation of various plots, one easy and very practical way to bundle and organize all steps of analysis together is to use R markdown files to generate PDF or html reports. These reports both display the R code used as well as the output generated, such as graphics, tables, statistical test results, \u2026 The difference between an R script and an R markdown file is that the code is organized within chunks in the R markdown file. In between the chunks, the user can write text that contains information about the analysis, package versions, links to websites, etc. To create an R markdown file, go to File > New File > R markdown. Add a name. This will create a new file that already has some example content. As you can see, the R code is organized in chunks highlighed in grey, with details written as free text in between the chunks. We can see that the pound sign (#) is used outside of the R code chunks. In this case, the # symbol does not correspond to a comment, but will indicate header levels for the titles and subtitles within your final document obtained after report generation. Once the Rmd is ready, the report can be generated by hitting the \u201cKnit\u201d button at the top of the window. The example Rmd generates the following html report (saved in the same folder as the Rmd file by default), that shows both the code and the resulting output: You can find a short video that introduces some of the principles of R markdown on Youtube , from the beginning up to minute 23:30. Starting at minute 23:30, this video also introduces ggplot2. Let\u2019s practice 11 To practice creating your own R markdown script, modify the one that is generated with the example content when you select File > New File > R Markdown. Create a new Rmd file with the following options at the top (in the top YAML instructions within the 2 dash sequences \u201c- - -\u201c) Title: \u00abLet\u2019s practice\u00bb Author: your name Select the \u00abuse current date when rendering object\u00bb option Default output format: HTML We will re-run the dimensional reduction exercise, but this time by creating a report. We will create an .Rmd file, and modify it to include the code for analysis and results of dimensional reduction of the FR_FCM_Z3WR data, using the code of Exercise 4 of Day 2. Now edit your .Rmd template: 1) Modify the YAML metadata section to include a table of content with numbered sections of 2 header levels, and buttons to hide the code. 2) Write a paragraph with a level-1 header, that describes the content of the document. 3) Create a chunk with global options that will print the R source code, include chunk outputs, and hide warnings and messages. 4) Create a chunk that will load the required libraries: flowCore, CATALYST, ggplot2, cowplot. 5) Create a code chunk for each of the following steps, that will run and/or print the output of the following analysis: a) Import the cleaned flowSet generated after cleaning with flowAI during Exercise 3, as well as the panel from the csv file. Important : modify the path that becomes relative to the location of the .Rmd script. Eg: load(\"../course_datasets/FR_FCM_Z3WR/fcs_clean.RData\") . Create a SingleCellExperiment object. b) Calculate the UMAP with default parameters, as in Exercise 4. c) Plot the UMAP, coloring the cells according to donor id and faceting according to time point. Set the chunk option to center the figure, using fig.align = \"center\" within the chunks option. d) Create additional chunks by playing with the plots: coloring according to some marker genes, etc. You can also arrange plots in grids using plot_grid() of the cowplot package. Have fun! 6) Save the Rmd file, knit the document to an html report and admire it in your web-browser! Download solution Rmd file For tweaking your reports, such as choosing different output formats, or hiding or showing the code within the report, we recommend that you consult the R markdown documentation provided in this Definite guide eBook . Another useful resource is RStudio\u2019s R Markdown tutorial . End of Day 4, good job!","title":"Exercises"},{"location":"flowCyt/day4/exercises_d4/#reporting-r-markdown","text":"If a data analysis project involves many steps and generation of various plots, one easy and very practical way to bundle and organize all steps of analysis together is to use R markdown files to generate PDF or html reports. These reports both display the R code used as well as the output generated, such as graphics, tables, statistical test results, \u2026 The difference between an R script and an R markdown file is that the code is organized within chunks in the R markdown file. In between the chunks, the user can write text that contains information about the analysis, package versions, links to websites, etc. To create an R markdown file, go to File > New File > R markdown. Add a name. This will create a new file that already has some example content. As you can see, the R code is organized in chunks highlighed in grey, with details written as free text in between the chunks. We can see that the pound sign (#) is used outside of the R code chunks. In this case, the # symbol does not correspond to a comment, but will indicate header levels for the titles and subtitles within your final document obtained after report generation. Once the Rmd is ready, the report can be generated by hitting the \u201cKnit\u201d button at the top of the window. The example Rmd generates the following html report (saved in the same folder as the Rmd file by default), that shows both the code and the resulting output: You can find a short video that introduces some of the principles of R markdown on Youtube , from the beginning up to minute 23:30. Starting at minute 23:30, this video also introduces ggplot2.","title":"Reporting - R Markdown"},{"location":"flowCyt/day4/exercises_d4/#lets-practice-11","text":"To practice creating your own R markdown script, modify the one that is generated with the example content when you select File > New File > R Markdown. Create a new Rmd file with the following options at the top (in the top YAML instructions within the 2 dash sequences \u201c- - -\u201c) Title: \u00abLet\u2019s practice\u00bb Author: your name Select the \u00abuse current date when rendering object\u00bb option Default output format: HTML We will re-run the dimensional reduction exercise, but this time by creating a report. We will create an .Rmd file, and modify it to include the code for analysis and results of dimensional reduction of the FR_FCM_Z3WR data, using the code of Exercise 4 of Day 2. Now edit your .Rmd template: 1) Modify the YAML metadata section to include a table of content with numbered sections of 2 header levels, and buttons to hide the code. 2) Write a paragraph with a level-1 header, that describes the content of the document. 3) Create a chunk with global options that will print the R source code, include chunk outputs, and hide warnings and messages. 4) Create a chunk that will load the required libraries: flowCore, CATALYST, ggplot2, cowplot. 5) Create a code chunk for each of the following steps, that will run and/or print the output of the following analysis: a) Import the cleaned flowSet generated after cleaning with flowAI during Exercise 3, as well as the panel from the csv file. Important : modify the path that becomes relative to the location of the .Rmd script. Eg: load(\"../course_datasets/FR_FCM_Z3WR/fcs_clean.RData\") . Create a SingleCellExperiment object. b) Calculate the UMAP with default parameters, as in Exercise 4. c) Plot the UMAP, coloring the cells according to donor id and faceting according to time point. Set the chunk option to center the figure, using fig.align = \"center\" within the chunks option. d) Create additional chunks by playing with the plots: coloring according to some marker genes, etc. You can also arrange plots in grids using plot_grid() of the cowplot package. Have fun! 6) Save the Rmd file, knit the document to an html report and admire it in your web-browser! Download solution Rmd file For tweaking your reports, such as choosing different output formats, or hiding or showing the code within the report, we recommend that you consult the R markdown documentation provided in this Definite guide eBook . Another useful resource is RStudio\u2019s R Markdown tutorial . End of Day 4, good job!","title":"Let's practice 11"},{"location":"flowCyt/day5/exercises_d5/","text":"In this section, you will find the R code that we will use during the course. We will explain the code and output during correction of the exercises.","title":"Exercises"},{"location":"introR/course_schedule/","text":"start end topic 10:30 10:50 Coffee break! 12:00 13:00 Lunch break! 15:30 15:50 Coffee break!","title":"Course schedule"},{"location":"introR/links/","text":"Here we provide some additional links Some tutorials to learn or practice R https://support.posit.co/hc/en-us/articles/200552336-Getting-Help-with-R https://r-coder.com/learn-r/ R for Data Science Book Book (2nd edition) by Hadley Wickham (a very active R developer), Mine \u00c7etinkaya-Rundel and Garrett Grolemund. The book makes heavy use of the tidyverse , which is a collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. ggplot2 is part of the tidyverse packages. https://r4ds.hadley.nz/ ggplot2 tutorial https://ggplot2.tidyverse.org/ R-charts A site that has been created to be a reference for learning how to create charts in R as well as a place to look for inspiration. Code examples to create plots with base R, ggplot2. Color charts with R color name vs HEX equivalent. https://r-charts.com/ R Markdown A useful resource is RStudio\u2019s R Markdown tutorial . For tweaking your reports, such as chosing different output formats, or hiding or showing the code within the report, we recommend that you consult the R markdown documentation provided in this Definite guide eBook . Cheatsheets Several cheatsheets available for different packages, eg R Markdown, ggplot2, RStudio,\u2026","title":"Useful links"},{"location":"introR/links/#some-tutorials-to-learn-or-practice-r","text":"https://support.posit.co/hc/en-us/articles/200552336-Getting-Help-with-R https://r-coder.com/learn-r/","title":"Some tutorials to learn or practice R"},{"location":"introR/links/#r-for-data-science-book","text":"Book (2nd edition) by Hadley Wickham (a very active R developer), Mine \u00c7etinkaya-Rundel and Garrett Grolemund. The book makes heavy use of the tidyverse , which is a collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. ggplot2 is part of the tidyverse packages. https://r4ds.hadley.nz/","title":"R for Data Science Book"},{"location":"introR/links/#ggplot2-tutorial","text":"https://ggplot2.tidyverse.org/","title":"ggplot2 tutorial"},{"location":"introR/links/#r-charts","text":"A site that has been created to be a reference for learning how to create charts in R as well as a place to look for inspiration. Code examples to create plots with base R, ggplot2. Color charts with R color name vs HEX equivalent. https://r-charts.com/","title":"R-charts"},{"location":"introR/links/#r-markdown","text":"A useful resource is RStudio\u2019s R Markdown tutorial . For tweaking your reports, such as chosing different output formats, or hiding or showing the code within the report, we recommend that you consult the R markdown documentation provided in this Definite guide eBook .","title":"R Markdown"},{"location":"introR/links/#cheatsheets","text":"Several cheatsheets available for different packages, eg R Markdown, ggplot2, RStudio,\u2026","title":"Cheatsheets"},{"location":"introR/material/","text":"Slides of lectures Day 1 Download slides - morning Download slides - afternoon Day 2 Download slides - morning Download essential slides - afternoon Download slides - afternoon Data for exercises Data for exercises of day 1 only Download course_datasets Data for all exercises, including day 2 (800 Mb data size) Download from the drive here , using Pwd 54321","title":"Material"},{"location":"introR/material/#slides-of-lectures","text":"","title":"Slides of lectures"},{"location":"introR/material/#day-1","text":"Download slides - morning Download slides - afternoon","title":"Day 1"},{"location":"introR/material/#day-2","text":"Download slides - morning Download essential slides - afternoon Download slides - afternoon","title":"Day 2"},{"location":"introR/material/#data-for-exercises","text":"","title":"Data for exercises"},{"location":"introR/material/#data-for-exercises-of-day-1-only","text":"Download course_datasets","title":"Data for exercises of day 1 only"},{"location":"introR/material/#data-for-all-exercises-including-day-2-800-mb-data-size","text":"Download from the drive here , using Pwd 54321","title":"Data for all exercises, including day 2 (800 Mb data size)"},{"location":"introR/precourse/","text":"R and RStudio Technical This course will be streamed via Zoom , you are thus required to have your own computer with an internet connection. Please, install the latest the version of R , followed by the installation of the free version of RStudio . At some point during the course, we will install R packages from within RStudio. This requires RStudio to access online repositories of packages and download them from the internet. Please ensure that this will not be blocked by firewalls.","title":"Precourse preparations"},{"location":"introR/precourse/#r-and-rstudio","text":"","title":"R and RStudio"},{"location":"introR/precourse/#technical","text":"This course will be streamed via Zoom , you are thus required to have your own computer with an internet connection. Please, install the latest the version of R , followed by the installation of the free version of RStudio . At some point during the course, we will install R packages from within RStudio. This requires RStudio to access online repositories of packages and download them from the internet. Please ensure that this will not be blocked by firewalls.","title":"Technical"},{"location":"introR/day1/exercises_d1/","text":"In this section, you will find the R code that we will use during the course. We will explain the code and output during correction of the exercises. First exploration of R using RStudio Four windows are displayed by default within RStudio. One of the windows corresponds to the R console. Type the following commands within the console (bottom left window in RStudio) at the prompt (\u201c>\u201d), followed by the \u201cEnter\u201d key after each one to view the output printed on the console. 1 + 1 The first command (1 + 1) prints \u201c2\u201d in the console. x <- 128.5 The second command does not print anything in the console, but a new variable called \u201cx\u201d and that contains the value 128.5 is created and listed in the Workspace (top right window in RStudio). x The third command prints the value stored within the \u201cx\u201d variable in the console. abs ( -11 ) The fourth command, with the use of the abs() function, prints the absolute value of -11 in the console. ? p.adjust Finally, the fifth command opens the help page for the p.adjust function (bottom right \u201cHelp\u201d window in RStudio). Working directory To manipulate data within R, we first need to import it. R needs a way to locate the files within the hard drive or system. Therefore, we can specify the working directory, i.e. the location where R will look for files. Warning To run the code below with setwd() make sure you put within the quotes a path that exists within your system. # To see what is the current working directory, use the function: getwd () # [1] \"C:/Users/twyss/Documents/Rcourse\" # To change the working directory to any existing folder on your hard drive or system, use setwd() and the file path within quotes, e.g. setwd ( \"D:/R_exercises/\" ) Workspace - Environment and history Once a value has been assigned to a named variable, as we did assigning 128.5 to x above, the variable is saved and listed within the Workspace, which is displayed in one of the RStudio windows. Explore your workspace using the command line: # To list the objects or variables that are in your workspace, type ls () # To remove (delete) an object from the workspace, use function rm(): rm ( x ) # To remove (delete) all objects from the workspace, type rm ( list = ls ()) Let\u2019s practice 2 - Create a script R scripts allow you to save all code for further use or reference. For big projects, it is essential to create an R script. To create a script, go to File > New File > R Script. Save it with file name \u201cex1.R\u201d or any other that is suitable for you. Add a comment symbol (#, the pound or hash sign) at the beginning of the first line. Type or paste the following code. Look at the script (before running it). Can you understand each line? What do you expect it to print to the console? Next, run the script and explore RStudio features such as the Workspace (Environment). Run the script line by line. Try both the \u201cRun\u201d button and the keyboard shortcut. Watch variables appear in the Environment window (top right). Watch what is printed to the console (bottom left window). Does it match your expectation? # First Steps and commands, ex. 1 w <- 3 h <- 0.5 area <- w * h area Packages When R is installed for the first time, a set of \u201cbase\u201d packages is installed along the R software. The list of available packages can be viewed in the package Explorer window within RStudio (bottom right \u201cPackages\u201d window). Each package is a bundle of functions designed and created by an author to perform specific, usually related tasks. When working with \u201cnon-standard\u201d data types, eg in bioinformatics or flow cytometry analysis, packages with bioinformatics-related functions need to be installed by the user. Common repositories for packages are CRAN and Bioconductor. Install packages from CRAN with the install.packages() function. To install packages hosted on Bioconductor , we need 2 steps. First, we install a package called BiocManager, that will allow us to have access to the install() function to download Bioconductor packages. # Install packages hosted on CRAN: use a function from the utils package: install.packages ( \"stringi\" ) # stringi is a package for character string manipulations install.packages ( \"rmarkdown\" ) # rmarkdown package that allows to create pdf reports (see day 2) # Install packages hosted on bioconductor: first install the BiocManager package that is available on CRAN: install.packages ( \"BiocManager\" ) # Then use the install() function from the BiocManager package # !! This takes time to complete, run it during coffee or lunch break! # Install flowCore: BiocManager :: install ( \"flowCore\" ) # Install ggcyto: BiocManager :: install ( \"ggcyto\" ) Once a package is installed, its content and functions need to be made accessible to R. library() loads the package for the current session. It is good practice to load all needed packages at the top of a script. # My Script library ( limma ) library ( DESeq2 ) library ( MASS ) library ( ggplot2 ) # Here my data analysis begins If you run the above code, what is the output on the Console? What does it mean? Answer Packages such as limma or DESeq2 are not installed as base packages. They are hosted on Bioconductor and provide functions for RNAseq or microarray data analysis. The error message indicates that these packages were not installed and need to be installed before being able to load them. R version and session information R is constantly upgraded by developers, which release a new version of R about every 6 months. Along with R upgrades, packages also get upgrades. From one version to the other of a package, it may happen that the default parameters of functions change. Therefore, it is important to always have in mind which current version of R and packages have been used for any analysis. Print the current R version and versions of attached or loaded packages using: # Prints the currently used R version R.version.string # Print version information about R and all attached or loaded packages sessionInfo () # Print the version of a specific package: packageVersion ( \"stringi\" ) Let\u2019s practice - 3 1) Assign the values 6.7 and 56.3 to variables a and b, respectively. 2) Calculate (2 a)/b + (a b) and assign the result to variable x. Display the content of x. 3) Find out how to compute the square root of variables. Compute the square roots of a and b and of the ratio a/b. 4) a) Calculate the logarithm to the base 2 of x (i.e., log2 x). b) Calculate the natural logarithm of x (i.e., loge x). Answer # 1) Assign the values 6.7 and 56.3 to variables \"a\" and \"b\", respectively. a <- 6.7 b <- 56.3 # 2) Calculate (2*a)/b + (a*b) and assign the result to variable \"x\". Display the content of \"x\". x <- ( 2 * a ) / b + a * b x # 3) Find out how to compute the square root of variables. Compute the square roots of \"a\" and \"b\" and of the ratio \"a/b\". sqrt ( a ) #using function sqrt() b ^ 0.5 # power 0.5 is the square root ( a / b ) ** 0.5 # another way of specifying power # 4) a) Calculate the logarithm to the base 2 of \"x\". # b) Calculate the natural logarithm of \"x\". log2 ( x ) # Function specifically for Log 2. Alternatively: log(x, base=2) log ( x ) # If we don't specify the base, default is the natural logarithm. Let\u2019s practice - 4 1) Create two vectors, vector_a and vector_b, containing values from \u22125 to 5 and from 10 down to 0, respectively. 2) Calculate the (element-wise) sum, difference and product between the elements of vector_a and vector_b. 3) a) Calculate the sum of elements in vector_a. b) Calculate the overall sum of elements in both vector_a and vector_b. 4) a) Identify the smallest and the largest value in vector_a b) among both vector_a and vector_b. 5) Compute the overall mean of the values among both vector_a and vector_b. Hint: Each task in exercises 1-5 can be performed in a single statement per vector (the minimum and maximum count as 2 tasks) Answer # 1) Create two vectors, \"vector_a\" and \"vector_b\", containing the values from \u22125 to 5 and from 10 down to 0, respectively. vector_a <- -5 : 5 vector_b <- seq ( 10 , 0 ) # alternatively: vector_b <- c(10,9,8,7,6,5,4,3,2,1,0) # 2) Calculate the (elementwise) sum, difference and product between the elements of \"vector_a\" and \"vector_b\". vector_a + vector_b #sum vector_a - vector_b #difference vector_a * vector_b #product # 3) a) Calculate the sum of elements in \"vector_a\" # b) Calculate the overall sum of elements in both \"vector_a\" and \"vector_b\". sum ( vector_a ) sum ( vector_a , vector_b ) # alternatively : sum(vector_a + vector_b) # 4) Identify the smallest and the largest value among both \"vector_a\" and \"vector_b\". min ( vector_a , vector_b ) max ( vector_a , vector_b ) # 5) Compute the overall mean of the values among both \"vector_a\" and \"vector_b\" mean ( c ( vector_a , vector_b ) ) # mean() works only on a single vector, unlike sum, min and max! # Concatenate both vectors (using c() ) before computing the mean Let\u2019s practice - 5 1) In your script, write the command to load the package \u201cMASS\u201d. 2) Write the following command to load the bacteria data set from the package MASS: data(bacteria) # loads the bacteria data set (from MASS) Execute the command. Check: You should have a variable named \u201cbacteria\u201d in your Environment/Workspace. 3) What are the names of the columns of the bacteria data.frame ? 4) Use [ ] to select rows 100 to 119 of the column \u201cap\u201d . 5) Use $ to get the column \u201cweek\u201d and check how many missing values it has. Optional : 6) Count how many rows correspond to a \u201cplacebo\u201d treatment (\u201ctrt\u201d column) using the comparison operator \u201c==\u201d. Answer # 1)Install and load the package MASS (or other CRAN packages). # install.packages(\"MASS\") library ( MASS ) # 2) The following command line loads the bacteria data.frame present in the MASS package. Execute it: data ( bacteria ) ? bacteria # 3) What are the names of the columns of the bacteria data.frame ? names ( bacteria ) # 4) Use the [ ] , to select in bacteria rows 100 to 119 in the column \"ap\". bacteria [ 100 : 119 , \"ap\" ] # 5) Use $ to get the column \"week\" and check how many missing values it has. sum ( is.na ( bacteria $ week )) # Optional : 6) use comparison operators to count how many rows correspond to a \u201cplacebo\u201d treatment (\u201ctrt\u201d column). sum ( bacteria $ trt == \"placebo\" ) Let\u2019s practice - 6 A clinical dataset from patients with lung cancer is available in the file clinical_data2.csv. The clinical_data2.csv file was generated from the clinical_data.csv source file using the following code: ## !! Adapt the path to the path in your own system if you wish to import the data available in file \"clinical_data.csv\" clinical_data <- read.csv ( \"course_datasets/clinical_data.csv\" ) # View the format of the data: head ( clinical_data ) # Number of rows and columns: dim ( clinical_data ) # Column names: colnames ( clinical_data ) # Structure of the data: str ( clinical_data ) # Convert the gender to a factor and re-order the disease stage: clinical_data $ gender <- factor ( clinical_data $ gender ) clinical_data $ stage <- factor ( clinical_data $ stage , levels = c ( \"I\" , \"II\" , \"III\" , \"IV\" )) str ( clinical_data ) # Obtain a summary for each variable: summary ( clinical_data ) # View the data in rown number 2: clinical_data [ 2 ,] # View the data in column named \"age\": clinical_data [, \"age\" ] # Check the element number 30 of the disease stage column clinical_data $ stage [ 30 ] # View the data corresponding to patients with stage II disease subset ( clinical_data , stage == \"II\" ) # View the data corresponding to patients with stage II disease and that are female: subset ( clinical_data , stage == \"II\" & gender == \"female\" ) # View the data corresponding to patients with stage I or II disease and that are female: subset ( clinical_data , ( stage == \"I\" | stage == \"II\" ) & gender == \"female\" ) tapply ( X = clinical_data $ age , INDEX = clinical_data $ stage , FUN = min ) # Add a new patient by concatenating rows and assign the result to a new variable called \"clinical_updated\": clinical_updated <- rbind ( clinical_data , data.frame ( sample_id = \"LC02\" , collection_date = \"18.02.2021\" , age = 71 , gender = \"female\" , stage = \"I\" )) # Create a new treated variable: treated <- rep ( c ( \"yes\" , \"no\" ), nrow ( clinical_data ) / 2 ) clinical_mod <- cbind ( treated , clinical_data ) # Remove the first column and view the format: clinical_orig <- clinical_mod [, -1 ] head ( clinical_orig ) clinical_orig <- clinical_mod [, 2 : dim ( clinical_mod )[ 2 ]] # Export to a new csv file: write.table ( clinical_updated , file = \"course_datasets/clinical_updated.csv\" , quote = FALSE , sep = \",\" , row.names = FALSE ) Let\u2019s explore the dataset to see what it contains. 1) Optional: Open a new script file in R studio, comment it and save it. 2) Have a look at the csv file in R studio\u2019s file explorer. What do you need to check in order to be able to read in the file correctly? 3) Read the file into R, assign its content to object \u201cclinical_data2\u201d. Examine the object. 4) How many observations and variables does the dataset have? 5) What is the structure of the dataset? What are the names and classes of the variables? 6) Which variables appear to be categorical? Convert them to factors. 7) Get the summary statistics of \u201cclinical_data2\u201d Answer # A clinical dataset from patients with lung cancer is available in the file clinical_data2.csv. # Let's explore the dataset to see what it contains. # 1) Open a new script file in R studio, comment it and save it. # 2) Have look at the csv file in R studio's file explorer. What do you need to check in order to be able to read in the file correctly? # 3) Read the file into R, assign its content to object \"clinical_data2\". Examine the object. # Adapt the path to the path in your own system! clinical_data2 <- read.csv ( \"course_datasets/clinical_data2.csv\" ) # 4) How many observations and variables does the dataset have? dim ( clinical_data2 ) # 5) What is the structure of the dataset? What are the names and classes of the variables? str ( clinical_data2 ) # 6) Which variables appear to be categorical? Convert them to factors. clinical_data2 $ gender <- factor ( clinical_data2 $ gender ) clinical_data2 $ stage <- factor ( clinical_data2 $ stage , levels = c ( \"I\" , \"II\" , \"III\" , \"IV\" )) clinical_data2 $ treatment_status <- factor ( clinical_data2 $ treatment_status ) clinical_data2 $ response_to_treatment <- factor ( clinical_data2 $ response_to_treatment , levels = c ( \"PD\" , \"SD\" , \"PR\" , \"CR\" )) # 7) Get the summary statistics of \"clinical_data2\" summary ( clinical_data2 ) Let\u2019s practice 6bis 8) Use the function table() to compute the number of samples in different patient groups. a) How many samples are included of each gender (male, female)? b) How many samples are included per level of response to treatment (PD, SD, PR, CR)? c) Make a 2x2 table gender and level of response to treatment. Hint : try some of the example in the help(table) page. 9) Isolate the samples from male patients using subset(). Compute a summary statistics just for the weights of the subset. Then do the same for the samples from female patients. Export the data of each subgroup to a csv file. 10) Compute the means and standard deviations for male and female patient weights using tapply(). Then do the same by level of response to treatment. Answer # 8) Use the function table() to compute the number of samples in different patient groups. # Hint : try some of the example in the help(table) page. # a) How many samples are included of each gender (male, female)? table ( clinical_data2 $ gender ) # b) How many samples are included per level of response to treatment (PD, SD, PR, CR)? table ( clinical_data2 $ response_to_treatment ) # c) Make a 2x2 table gender and level of response to treatment. table ( clinical_data2 [, c ( \"gender\" , \"response_to_treatment\" )]) # 9) Isolate the samples from male patients using subset(). # Compute a summary statistics just for the weights of the subset. # Then do the same for the samples from female patients. # Export the data of each subgroup to a csv file. # Isolate the samples from male patients clinical_data2_male <- subset ( clinical_data2 , gender == \"male\" ) # Compute a summary statistics just for the weights of the subset summary ( clinical_data2_male $ weight ) # Export the data to a csv file. write.table ( clinical_data2_male , file = \"course_datasets/clinical_data2_male.csv\" , quote = FALSE , sep = \",\" , row.names = FALSE ) # Isolate the samples from female patients clinical_data2_female <- subset ( clinical_data2 , gender == \"female\" ) # Compute a summary statistics just for the weights of the subset summary ( clinical_data2_female $ weight ) # Export the data to a csv file. write.table ( clinical_data2_female , file = \"course_datasets/clinical_data2_female.csv\" , quote = FALSE , sep = \",\" , row.names = FALSE ) # 10) Compute the means and standard deviations for male and female patient weights using tapply(). # Then do the same by level of response to treatment. # by gender tapply ( clinical_data2 $ weight , clinical_data2 $ gender , mean ) # mean: by gender tapply ( clinical_data2 $ weight , clinical_data2 $ gender , sd ) # standard deviation by gender # by response to treatment tapply ( clinical_data2 $ weight , clinical_data2 $ response_to_treatment , mean ) # mean: by level of response to treatment tapply ( clinical_data2 $ weight , clinical_data2 $ response_to_treatment , sd ) # standard deviation by level of response to treatment End of Day 1, good job!","title":"Exercises"},{"location":"introR/day1/exercises_d1/#first-exploration-of-r-using-rstudio","text":"Four windows are displayed by default within RStudio. One of the windows corresponds to the R console. Type the following commands within the console (bottom left window in RStudio) at the prompt (\u201c>\u201d), followed by the \u201cEnter\u201d key after each one to view the output printed on the console. 1 + 1 The first command (1 + 1) prints \u201c2\u201d in the console. x <- 128.5 The second command does not print anything in the console, but a new variable called \u201cx\u201d and that contains the value 128.5 is created and listed in the Workspace (top right window in RStudio). x The third command prints the value stored within the \u201cx\u201d variable in the console. abs ( -11 ) The fourth command, with the use of the abs() function, prints the absolute value of -11 in the console. ? p.adjust Finally, the fifth command opens the help page for the p.adjust function (bottom right \u201cHelp\u201d window in RStudio).","title":"First exploration of R using RStudio"},{"location":"introR/day1/exercises_d1/#working-directory","text":"To manipulate data within R, we first need to import it. R needs a way to locate the files within the hard drive or system. Therefore, we can specify the working directory, i.e. the location where R will look for files. Warning To run the code below with setwd() make sure you put within the quotes a path that exists within your system. # To see what is the current working directory, use the function: getwd () # [1] \"C:/Users/twyss/Documents/Rcourse\" # To change the working directory to any existing folder on your hard drive or system, use setwd() and the file path within quotes, e.g. setwd ( \"D:/R_exercises/\" )","title":"Working directory"},{"location":"introR/day1/exercises_d1/#workspace-environment-and-history","text":"Once a value has been assigned to a named variable, as we did assigning 128.5 to x above, the variable is saved and listed within the Workspace, which is displayed in one of the RStudio windows. Explore your workspace using the command line: # To list the objects or variables that are in your workspace, type ls () # To remove (delete) an object from the workspace, use function rm(): rm ( x ) # To remove (delete) all objects from the workspace, type rm ( list = ls ())","title":"Workspace - Environment and history"},{"location":"introR/day1/exercises_d1/#lets-practice-2-create-a-script","text":"R scripts allow you to save all code for further use or reference. For big projects, it is essential to create an R script. To create a script, go to File > New File > R Script. Save it with file name \u201cex1.R\u201d or any other that is suitable for you. Add a comment symbol (#, the pound or hash sign) at the beginning of the first line. Type or paste the following code. Look at the script (before running it). Can you understand each line? What do you expect it to print to the console? Next, run the script and explore RStudio features such as the Workspace (Environment). Run the script line by line. Try both the \u201cRun\u201d button and the keyboard shortcut. Watch variables appear in the Environment window (top right). Watch what is printed to the console (bottom left window). Does it match your expectation? # First Steps and commands, ex. 1 w <- 3 h <- 0.5 area <- w * h area","title":"Let's practice 2 - Create a script"},{"location":"introR/day1/exercises_d1/#packages","text":"When R is installed for the first time, a set of \u201cbase\u201d packages is installed along the R software. The list of available packages can be viewed in the package Explorer window within RStudio (bottom right \u201cPackages\u201d window). Each package is a bundle of functions designed and created by an author to perform specific, usually related tasks. When working with \u201cnon-standard\u201d data types, eg in bioinformatics or flow cytometry analysis, packages with bioinformatics-related functions need to be installed by the user. Common repositories for packages are CRAN and Bioconductor. Install packages from CRAN with the install.packages() function. To install packages hosted on Bioconductor , we need 2 steps. First, we install a package called BiocManager, that will allow us to have access to the install() function to download Bioconductor packages. # Install packages hosted on CRAN: use a function from the utils package: install.packages ( \"stringi\" ) # stringi is a package for character string manipulations install.packages ( \"rmarkdown\" ) # rmarkdown package that allows to create pdf reports (see day 2) # Install packages hosted on bioconductor: first install the BiocManager package that is available on CRAN: install.packages ( \"BiocManager\" ) # Then use the install() function from the BiocManager package # !! This takes time to complete, run it during coffee or lunch break! # Install flowCore: BiocManager :: install ( \"flowCore\" ) # Install ggcyto: BiocManager :: install ( \"ggcyto\" ) Once a package is installed, its content and functions need to be made accessible to R. library() loads the package for the current session. It is good practice to load all needed packages at the top of a script. # My Script library ( limma ) library ( DESeq2 ) library ( MASS ) library ( ggplot2 ) # Here my data analysis begins If you run the above code, what is the output on the Console? What does it mean? Answer Packages such as limma or DESeq2 are not installed as base packages. They are hosted on Bioconductor and provide functions for RNAseq or microarray data analysis. The error message indicates that these packages were not installed and need to be installed before being able to load them.","title":"Packages"},{"location":"introR/day1/exercises_d1/#r-version-and-session-information","text":"R is constantly upgraded by developers, which release a new version of R about every 6 months. Along with R upgrades, packages also get upgrades. From one version to the other of a package, it may happen that the default parameters of functions change. Therefore, it is important to always have in mind which current version of R and packages have been used for any analysis. Print the current R version and versions of attached or loaded packages using: # Prints the currently used R version R.version.string # Print version information about R and all attached or loaded packages sessionInfo () # Print the version of a specific package: packageVersion ( \"stringi\" )","title":"R version and session information"},{"location":"introR/day1/exercises_d1/#lets-practice-3","text":"1) Assign the values 6.7 and 56.3 to variables a and b, respectively. 2) Calculate (2 a)/b + (a b) and assign the result to variable x. Display the content of x. 3) Find out how to compute the square root of variables. Compute the square roots of a and b and of the ratio a/b. 4) a) Calculate the logarithm to the base 2 of x (i.e., log2 x). b) Calculate the natural logarithm of x (i.e., loge x). Answer # 1) Assign the values 6.7 and 56.3 to variables \"a\" and \"b\", respectively. a <- 6.7 b <- 56.3 # 2) Calculate (2*a)/b + (a*b) and assign the result to variable \"x\". Display the content of \"x\". x <- ( 2 * a ) / b + a * b x # 3) Find out how to compute the square root of variables. Compute the square roots of \"a\" and \"b\" and of the ratio \"a/b\". sqrt ( a ) #using function sqrt() b ^ 0.5 # power 0.5 is the square root ( a / b ) ** 0.5 # another way of specifying power # 4) a) Calculate the logarithm to the base 2 of \"x\". # b) Calculate the natural logarithm of \"x\". log2 ( x ) # Function specifically for Log 2. Alternatively: log(x, base=2) log ( x ) # If we don't specify the base, default is the natural logarithm.","title":"Let's practice - 3"},{"location":"introR/day1/exercises_d1/#lets-practice-4","text":"1) Create two vectors, vector_a and vector_b, containing values from \u22125 to 5 and from 10 down to 0, respectively. 2) Calculate the (element-wise) sum, difference and product between the elements of vector_a and vector_b. 3) a) Calculate the sum of elements in vector_a. b) Calculate the overall sum of elements in both vector_a and vector_b. 4) a) Identify the smallest and the largest value in vector_a b) among both vector_a and vector_b. 5) Compute the overall mean of the values among both vector_a and vector_b. Hint: Each task in exercises 1-5 can be performed in a single statement per vector (the minimum and maximum count as 2 tasks) Answer # 1) Create two vectors, \"vector_a\" and \"vector_b\", containing the values from \u22125 to 5 and from 10 down to 0, respectively. vector_a <- -5 : 5 vector_b <- seq ( 10 , 0 ) # alternatively: vector_b <- c(10,9,8,7,6,5,4,3,2,1,0) # 2) Calculate the (elementwise) sum, difference and product between the elements of \"vector_a\" and \"vector_b\". vector_a + vector_b #sum vector_a - vector_b #difference vector_a * vector_b #product # 3) a) Calculate the sum of elements in \"vector_a\" # b) Calculate the overall sum of elements in both \"vector_a\" and \"vector_b\". sum ( vector_a ) sum ( vector_a , vector_b ) # alternatively : sum(vector_a + vector_b) # 4) Identify the smallest and the largest value among both \"vector_a\" and \"vector_b\". min ( vector_a , vector_b ) max ( vector_a , vector_b ) # 5) Compute the overall mean of the values among both \"vector_a\" and \"vector_b\" mean ( c ( vector_a , vector_b ) ) # mean() works only on a single vector, unlike sum, min and max! # Concatenate both vectors (using c() ) before computing the mean","title":"Let's practice - 4"},{"location":"introR/day1/exercises_d1/#lets-practice-5","text":"1) In your script, write the command to load the package \u201cMASS\u201d. 2) Write the following command to load the bacteria data set from the package MASS: data(bacteria) # loads the bacteria data set (from MASS) Execute the command. Check: You should have a variable named \u201cbacteria\u201d in your Environment/Workspace. 3) What are the names of the columns of the bacteria data.frame ? 4) Use [ ] to select rows 100 to 119 of the column \u201cap\u201d . 5) Use $ to get the column \u201cweek\u201d and check how many missing values it has. Optional : 6) Count how many rows correspond to a \u201cplacebo\u201d treatment (\u201ctrt\u201d column) using the comparison operator \u201c==\u201d. Answer # 1)Install and load the package MASS (or other CRAN packages). # install.packages(\"MASS\") library ( MASS ) # 2) The following command line loads the bacteria data.frame present in the MASS package. Execute it: data ( bacteria ) ? bacteria # 3) What are the names of the columns of the bacteria data.frame ? names ( bacteria ) # 4) Use the [ ] , to select in bacteria rows 100 to 119 in the column \"ap\". bacteria [ 100 : 119 , \"ap\" ] # 5) Use $ to get the column \"week\" and check how many missing values it has. sum ( is.na ( bacteria $ week )) # Optional : 6) use comparison operators to count how many rows correspond to a \u201cplacebo\u201d treatment (\u201ctrt\u201d column). sum ( bacteria $ trt == \"placebo\" )","title":"Let's practice - 5"},{"location":"introR/day1/exercises_d1/#lets-practice-6","text":"A clinical dataset from patients with lung cancer is available in the file clinical_data2.csv. The clinical_data2.csv file was generated from the clinical_data.csv source file using the following code: ## !! Adapt the path to the path in your own system if you wish to import the data available in file \"clinical_data.csv\" clinical_data <- read.csv ( \"course_datasets/clinical_data.csv\" ) # View the format of the data: head ( clinical_data ) # Number of rows and columns: dim ( clinical_data ) # Column names: colnames ( clinical_data ) # Structure of the data: str ( clinical_data ) # Convert the gender to a factor and re-order the disease stage: clinical_data $ gender <- factor ( clinical_data $ gender ) clinical_data $ stage <- factor ( clinical_data $ stage , levels = c ( \"I\" , \"II\" , \"III\" , \"IV\" )) str ( clinical_data ) # Obtain a summary for each variable: summary ( clinical_data ) # View the data in rown number 2: clinical_data [ 2 ,] # View the data in column named \"age\": clinical_data [, \"age\" ] # Check the element number 30 of the disease stage column clinical_data $ stage [ 30 ] # View the data corresponding to patients with stage II disease subset ( clinical_data , stage == \"II\" ) # View the data corresponding to patients with stage II disease and that are female: subset ( clinical_data , stage == \"II\" & gender == \"female\" ) # View the data corresponding to patients with stage I or II disease and that are female: subset ( clinical_data , ( stage == \"I\" | stage == \"II\" ) & gender == \"female\" ) tapply ( X = clinical_data $ age , INDEX = clinical_data $ stage , FUN = min ) # Add a new patient by concatenating rows and assign the result to a new variable called \"clinical_updated\": clinical_updated <- rbind ( clinical_data , data.frame ( sample_id = \"LC02\" , collection_date = \"18.02.2021\" , age = 71 , gender = \"female\" , stage = \"I\" )) # Create a new treated variable: treated <- rep ( c ( \"yes\" , \"no\" ), nrow ( clinical_data ) / 2 ) clinical_mod <- cbind ( treated , clinical_data ) # Remove the first column and view the format: clinical_orig <- clinical_mod [, -1 ] head ( clinical_orig ) clinical_orig <- clinical_mod [, 2 : dim ( clinical_mod )[ 2 ]] # Export to a new csv file: write.table ( clinical_updated , file = \"course_datasets/clinical_updated.csv\" , quote = FALSE , sep = \",\" , row.names = FALSE ) Let\u2019s explore the dataset to see what it contains. 1) Optional: Open a new script file in R studio, comment it and save it. 2) Have a look at the csv file in R studio\u2019s file explorer. What do you need to check in order to be able to read in the file correctly? 3) Read the file into R, assign its content to object \u201cclinical_data2\u201d. Examine the object. 4) How many observations and variables does the dataset have? 5) What is the structure of the dataset? What are the names and classes of the variables? 6) Which variables appear to be categorical? Convert them to factors. 7) Get the summary statistics of \u201cclinical_data2\u201d Answer # A clinical dataset from patients with lung cancer is available in the file clinical_data2.csv. # Let's explore the dataset to see what it contains. # 1) Open a new script file in R studio, comment it and save it. # 2) Have look at the csv file in R studio's file explorer. What do you need to check in order to be able to read in the file correctly? # 3) Read the file into R, assign its content to object \"clinical_data2\". Examine the object. # Adapt the path to the path in your own system! clinical_data2 <- read.csv ( \"course_datasets/clinical_data2.csv\" ) # 4) How many observations and variables does the dataset have? dim ( clinical_data2 ) # 5) What is the structure of the dataset? What are the names and classes of the variables? str ( clinical_data2 ) # 6) Which variables appear to be categorical? Convert them to factors. clinical_data2 $ gender <- factor ( clinical_data2 $ gender ) clinical_data2 $ stage <- factor ( clinical_data2 $ stage , levels = c ( \"I\" , \"II\" , \"III\" , \"IV\" )) clinical_data2 $ treatment_status <- factor ( clinical_data2 $ treatment_status ) clinical_data2 $ response_to_treatment <- factor ( clinical_data2 $ response_to_treatment , levels = c ( \"PD\" , \"SD\" , \"PR\" , \"CR\" )) # 7) Get the summary statistics of \"clinical_data2\" summary ( clinical_data2 )","title":"Let's practice - 6"},{"location":"introR/day1/exercises_d1/#lets-practice-6bis","text":"8) Use the function table() to compute the number of samples in different patient groups. a) How many samples are included of each gender (male, female)? b) How many samples are included per level of response to treatment (PD, SD, PR, CR)? c) Make a 2x2 table gender and level of response to treatment. Hint : try some of the example in the help(table) page. 9) Isolate the samples from male patients using subset(). Compute a summary statistics just for the weights of the subset. Then do the same for the samples from female patients. Export the data of each subgroup to a csv file. 10) Compute the means and standard deviations for male and female patient weights using tapply(). Then do the same by level of response to treatment. Answer # 8) Use the function table() to compute the number of samples in different patient groups. # Hint : try some of the example in the help(table) page. # a) How many samples are included of each gender (male, female)? table ( clinical_data2 $ gender ) # b) How many samples are included per level of response to treatment (PD, SD, PR, CR)? table ( clinical_data2 $ response_to_treatment ) # c) Make a 2x2 table gender and level of response to treatment. table ( clinical_data2 [, c ( \"gender\" , \"response_to_treatment\" )]) # 9) Isolate the samples from male patients using subset(). # Compute a summary statistics just for the weights of the subset. # Then do the same for the samples from female patients. # Export the data of each subgroup to a csv file. # Isolate the samples from male patients clinical_data2_male <- subset ( clinical_data2 , gender == \"male\" ) # Compute a summary statistics just for the weights of the subset summary ( clinical_data2_male $ weight ) # Export the data to a csv file. write.table ( clinical_data2_male , file = \"course_datasets/clinical_data2_male.csv\" , quote = FALSE , sep = \",\" , row.names = FALSE ) # Isolate the samples from female patients clinical_data2_female <- subset ( clinical_data2 , gender == \"female\" ) # Compute a summary statistics just for the weights of the subset summary ( clinical_data2_female $ weight ) # Export the data to a csv file. write.table ( clinical_data2_female , file = \"course_datasets/clinical_data2_female.csv\" , quote = FALSE , sep = \",\" , row.names = FALSE ) # 10) Compute the means and standard deviations for male and female patient weights using tapply(). # Then do the same by level of response to treatment. # by gender tapply ( clinical_data2 $ weight , clinical_data2 $ gender , mean ) # mean: by gender tapply ( clinical_data2 $ weight , clinical_data2 $ gender , sd ) # standard deviation by gender # by response to treatment tapply ( clinical_data2 $ weight , clinical_data2 $ response_to_treatment , mean ) # mean: by level of response to treatment tapply ( clinical_data2 $ weight , clinical_data2 $ response_to_treatment , sd ) # standard deviation by level of response to treatment End of Day 1, good job!","title":"Let's practice 6bis"},{"location":"introR/day2/exercises_d2/","text":"In this section, you will find the R code that we will use during the course. We will explain the code and output during correction of the exercises. R offers many options for creating graphics and figures. Two common ways to create graphics within R use \u201cbase\u201d functions such as plot(), or functions of the package ggplot2 . So many possible chart types exist, and some are better than others at representing different data types. The online tool \u201cFrom Data to Viz\u201d provides a nice decision tree to suggest a set of potentially appropriate graphics to visualize the dataset according to the input data format and type. Feel free to explore the decision tree! Most of the graphics suggested by \u201cData to Viz\u201d are generated with ggplot2 functions and other packages providing extensions for ggplot2 functions. In these exercises, we will create graphics using the \u201cbase\u201d R functions, i.e. functions of the graphics package that is installed at the same time as R is installed. Let\u2019s practice 7 Import the clinical data from the file clinical_data_mod.csv. This files contains the same data as clinical_data.csv and in addition, one more column. 1) Run str() to check your data frame: did it load correctly? 2) Convert gender and response_to_treatment to factor variables. 3) Plot a histogram of patient weight and customize it with colours, labels, title. 4) Make a scatter plot of height against patient weights using the function plot(). Function arguments: use solid circles as plotting symbol add a title customize the axis labels (\u201cWeight [kg]\u201d, \u201cHeight [m]\u201d) color the points by gender. Add a legend for the gender. Fit a trend line using the function abline(). 5) Create a new column called \u201cBMI\u201d and compute the BMI of patients from their weight and height 6) Make boxplots of BMI from patients with different responses to treatment. Customize with title, labels, colors. Add points to the boxplots to show the individual values. 7) Optional: Repeat 6 with stage, instead of response to treatment. Hint: what kind of variable is stage? Answer clinical_data <- read.table ( \"course_datasets/clinical_data_mod.csv\" , header = TRUE , sep = \",\" ) # define classes for columns str ( clinical_data ) # 2) Convert gender and response_to_treatment to factor variables # define the order of factor levels clinical_data $ gender <- factor ( clinical_data $ gender ) clinical_data $ response_to_treatment <- factor ( clinical_data $ response_to_treatment , levels = c ( \"PD\" , \"SD\" , \"PR\" , \"CR\" )) # 3) Plot an histogram of patient weight and customize it with colours, labels, title and represent the density line on top. hist ( clinical_data $ weight , freq = FALSE , breaks = 8 , main = \"Patient Weight\" , col = \"orange\" , xlab = \"Weight [kg]\" ) # lines(density(clinical_data$weight), col='blue') # Note: freq=FALSE makes the histogram density based, which makes it scale well with the density line # 4) Make a scatter plot of height against patient weights using the function plot(). # Function arguments: # - use solid circles as plotting symbol # - add a title # - customise the axis labels (\u201cWeight [kg]\u201d, \u201cHeight [m]\u201d) # - colour the points by gender. # Add a legend for the gender. plot ( clinical_data $ weight , clinical_data $ height , pch = 19 , main = \"Weight vs Height in Patients\" , xlab = \"Weight [kg]\" , ylab = \"Height [m]\" , col = c ( \"orange\" , \"blue\" )[ clinical_data $ gender ] ) legend ( \"bottomright\" , legend = levels ( clinical_data $ gender ), col = c ( \"orange\" , \"blue\" ), pch = 19 ) abline ( lm ( clinical_data $ height ~ clinical_data $ weight ), col = \"black\" , lwd = 1.5 ) # 5) Compute the BMI = Weight / Height^2 clinical_data $ BMI <- clinical_data $ weight / ( clinical_data $ height ^ 2 ) # 6) Make boxplots of BMIs from patients with different responses to treatment. Customize with title, labels, colors. boxplot ( BMI ~ response_to_treatment , data = clinical_data , col = c ( \"red\" , \"orange\" , \"green\" , \"blue\" ), main = \"BMI by level of Response to treatment\" , xlab = \"Response to treatment\" , ylab = \"BMI\" ) points ( BMI ~ response_to_treatment , data = clinical_data ) # 7) Optional: Repeat 6 with BMI and stage, instead of weight and gender. clinical_data $ stage <- factor ( clinical_data $ stage , levels = c ( \"I\" , \"II\" , \"III\" , \"IV\" )) boxplot ( BMI ~ stage , data = clinical_data , col = c ( \"blue\" , \"green\" , \"orange\" , \"red\" ), main = \"Patient BMI by Stage\" , xlab = \"Stage\" , ylab = \"BMI\" ) points ( BMI ~ stage , data = clinical_data ) getwd () # check where you are. If you didn't change anything, you will be in the folder with the .Rproj file (rproject root) Let\u2019s practice 8 1) Create a multi-panel figure with the four graphics (3, 4, 6 and 7 from the previous exercise) on one page, exporting the figure to a pdf file with paper size A4. Set width and height arguments in the call to pdf() to make it look nice. 2) Optional: Export the histogram (3 from previous exercise) to a png file. Set the width and height arguments in the call to png() to make it look nice. Answer # 1) Make a multi-panel figure with the four graphics on one page, exporting the figure to a png file. # Set width and height arguments in the call to png() to make it look nice. pdf ( \"clinical_data_plots.pdf\" , width = 7 , height = 7 , paper = \"a4\" ) # we want to put 4 plots on the same panel -> 2 rows and 2 columns par ( mfrow = c ( 2 , 2 )) # Plot 1 hist ( clinical_data $ weight , freq = FALSE , breaks = 8 , main = \"Patient Weight\" , col = \"orange\" , xlab = \"Weight [kg]\" ) lines ( density ( clinical_data $ weight ), col = 'blue' ) # Plot 2 plot ( clinical_data $ weight , clinical_data $ height , pch = 19 , main = \"Weight vs Height in Patients\" , xlab = \"Weight [kg]\" , ylab = \"Height [m]\" , col = c ( \"orange\" , \"blue\" )[ clinical_data $ gender ] ) legend ( \"bottomright\" , legend = levels ( clinical_data $ gender ), col = c ( \"orange\" , \"blue\" ), pch = 19 ) abline ( lm ( clinical_data $ height ~ clinical_data $ weight ), col = \"black\" , lwd = 1.5 ) # Plot 3 boxplot ( BMI ~ response_to_treatment , data = clinical_data , col = c ( \"red\" , \"orange\" , \"green\" , \"blue\" ), main = \"BMI by level of Response to treatment\" , xlab = \"Response to treatment\" , ylab = \"BMI\" ) points ( BMI ~ response_to_treatment , data = clinical_data ) # Plot 4 boxplot ( BMI ~ stage , data = clinical_data , col = c ( \"blue\" , \"green\" , \"orange\" , \"red\" ), main = \"Patient BMI by Stage\" , xlab = \"Stage\" , ylab = \"BMI\" ) points ( BMI ~ stage , data = clinical_data ) dev.off () # 2) Optional: Export the histogram (3 from previous exercise) to a png file. # Set width and height arguments in the call to png() to make it look nice. # png: width and height are in pixels by default png ( \"hist_weight.png\" , width = 800 , height = 600 ) hist ( clinical_data $ weight , freq = FALSE , breaks = 8 , main = \"Patient Weight\" , col = \"orange\" , xlab = \"Weight [kg]\" ) lines ( density ( clinical_data $ weight ), col = 'blue' ) dev.off () Bonus Create plots with ggplot2 . ggplot2 is a package that allows you to create graphics by adding customization \u201clayers\u201d one after the other. You first provide the data, tell ggplot2 how to map variables to aesthetics (i.e. the variables you want to have on the x and y coordinates), what plot type to use, and it provides some default colors for the categorical variables, and automatic legend positioning. Everything can then be further customized by the user by adding additional layers using ggplot2 functions. library ( ggplot2 ) # Import data: clinical_data <- read.table ( \"course_datasets/clinical_data_mod.csv\" , header = TRUE , sep = \",\" ) # define classes for columns str ( clinical_data ) # Convert gender to factor variables clinical_data $ gender <- factor ( clinical_data $ gender ) # Compute the BMI = Weight / Height^2 clinical_data $ BMI <- clinical_data $ weight / ( clinical_data $ height ^ 2 ) # Simple boxplot of BMI vs stage ggplot ( data = clinical_data , aes ( x = stage , y = BMI )) + geom_boxplot () # Boxplot of BMI vs stage, coloring according to stage # With legend: ggplot ( data = clinical_data , aes ( x = stage , y = BMI , color = stage )) + geom_boxplot () # Boxplot of BMI vs stage, coloring according to stage, flipping orientation ggplot ( data = clinical_data , aes ( x = stage , y = BMI , color = stage )) + geom_boxplot () + coord_flip () # Without legend: ggplot ( data = clinical_data , aes ( x = stage , y = BMI , color = stage )) + geom_boxplot () + theme ( legend.position = \"none\" ) # Scatter plot of weight vs height, coloring by gender ggplot ( data = clinical_data , aes ( x = weight , y = height , color = gender )) + geom_point () # Compare plot generated earlier with base R to the one with ggplot2: # Reproduce Plot 2 of exercise 8 plot ( clinical_data $ weight , clinical_data $ height , pch = 19 , main = \"Weight vs Height in Patients\" , xlab = \"Weight [kg]\" , ylab = \"Height [m]\" , col = c ( \"orange\" , \"blue\" )[ clinical_data $ gender ]) legend ( \"bottomright\" , legend = levels ( clinical_data $ gender ), col = c ( \"orange\" , \"blue\" ), pch = 19 ) abline ( lm ( clinical_data $ height ~ clinical_data $ weight ), col = \"black\" , lwd = 1.5 ) # Same plot with ggplot2 # Scatter plot of weight vs height, coloring by gender ggplot ( data = clinical_data , aes ( x = weight , y = height , color = gender )) + geom_point () + scale_color_manual ( values = c ( \"female\" = \"orange\" , \"male\" = \"blue\" )) + ggtitle ( \"Weight vs Height in Patients\" ) + xlab ( \"Weight [kg]\" ) + ylab ( \"Height [m]\" ) + theme_bw () + geom_smooth ( method = \"lm\" , formula = y ~ x , se = TRUE ) # display confidence interval around smoothed curve # Create a separate plot for males and females: # Use Facet wrap: separate the plots according to a categorical (factor) variable ggplot ( data = clinical_data , aes ( x = weight , y = height , color = gender )) + geom_point () + scale_color_manual ( values = c ( \"female\" = \"orange\" , \"male\" = \"blue\" )) + ggtitle ( \"Weight vs Height in Patients\" ) + xlab ( \"Weight [kg]\" ) + ylab ( \"Height [m]\" ) + theme_bw () + geom_smooth ( method = \"lm\" , formula = y ~ x , se = TRUE ) + facet_wrap ( ~ gender ) ### Multi panel figures with ggplot2 # save each plot in an object, create 2 plots that are the same except for the color of the dots p1 <- ggplot ( data = clinical_data , aes ( x = weight , y = height , color = gender )) + geom_point () + scale_color_manual ( values = c ( \"female\" = \"orange\" , \"male\" = \"blue\" )) + ggtitle ( \"Weight vs Height in Patients\" ) + xlab ( \"Weight [kg]\" ) + ylab ( \"Height [m]\" ) + theme_bw () p2 <- ggplot ( data = clinical_data , aes ( x = weight , y = height , color = gender )) + geom_point () + scale_color_manual ( values = c ( \"female\" = \"turquoise\" , \"male\" = \"plum\" )) + ggtitle ( \"Weight vs Height in Patients\" ) + xlab ( \"Weight [kg]\" ) + ylab ( \"Height [m]\" ) + theme_bw () # install the cowplot package to arrange several plots on a single page # install.packages(\"cowplot\") library ( cowplot ) plot_grid ( p1 , p2 , nrow = 1 ) Let\u2019s practice 9 In this exercise we will use a 36-color spectral flow cytometry dataset from a study performed in the context of Covid-19 research. Only a subset from 4 healthy donors will be used. For each healthy donor, there are three time points, as indicated in the FCS file names (day 0, day 7, day 14). Data was downloaded through the Flow Repository database, FR-FCM-Z3WR . FCS files were pre-gated on live CD3+CD19-T cells in FlowJo. Create a new script in which you will: 1) Import the FCS files (located in course_datasets/FR_FCM_Z3WR/). Do not transform or truncate the values. 2) Create a data frame with the list of channels and corresponding antigens, and plot it. Hint: get the antigens from the parameters of one of the flowFrame in the set 3) Convert the channel names in the expression matrices to the corresponding antigen names (where applicable) 4) Add a new column to the phenotypic data with the time point of the sample. Plot the phenotypic data 5) Create a bivariate density plot showing \u00abFSC-H\u00bb againts \u00abHLA-DR\u00bb for all samples from day 0. Apply a flowJo inverse hyperbolic sine scale to the y axis (\u00abHLA-DR\u00bb) Answer # load packages library ( flowCore ) library ( ggcyto ) # 1) Import the FCS files (course_datasets/FR_FCM_Z3WR/). # Do not transform or truncate the values. # path to the directory with the fcs files fcs.dir <- file.path ( \"course_datasets/FR_FCM_Z3WR/\" ) # read fcs files into a flowSet fcs_data <- read.flowSet ( path = fcs.dir , pattern = \"*.fcs\" , transformation = FALSE , truncate_max_range = FALSE ) #2) Create a data frame with the list of channels and corresponding antigens, and plot it. #Hint: get the antigens from the parameters of one of the flowFrame in the set channels <- colnames ( fcs_data ) antigen <- pData ( parameters ( fcs_data [[ 1 ]])) $ desc panel <- data.frame ( channels = channels , antigen = antigen ) # View the panel in the console panel #3) Convert the channel names in the expression matrices to the # corresponding antigen names (where applicable) colnames ( fcs_data )[ ! is.na ( antigen )] <- antigen [ ! is.na ( antigen )] # check head ( exprs ( fcs_data [[ 1 ]])[, c ( 5 : 10 )]) #4) Add a new column to the phenotypic data with the time point of the sample # check sample names sampleNames ( fcs_data ) # [1] \"0E1F8E_0.fcs\" \"0E1F8E_14.fcs\" \"0E1F8E_7.fcs\" \"180E1A_0.fcs\" \"180E1A_14.fcs\" \"180E1A_7.fcs\" # [7] \"1A9B20_0.fcs\" \"1A9B20_14.fcs\" \"1A9B20_7.fcs\" \"61BBAD_0.fcs\" \"61BBAD_14.fcs\" \"61BBAD_7.fcs\" # add column with time point pData ( fcs_data ) $ time_point <- rep ( c ( \"D0\" , \"D14\" , \"D7\" ), 4 ) # View the phenotypic data pData ( fcs_data ) # 5) Create a bivariate density plot showing \"FSC-H\" against \"HLA-DR\" for all samples from day 0. # Apply a flowJO inverse hyperbolic sine scale to the y axis (\"HLA-DR\") # split by time point fcs_data.split <- split ( fcs_data , pData ( fcs_data ) $ time_point ) # create the bivariate density plot autoplot ( fcs_data.split $ D0 , x = \"FSC-H\" , y = \"HLA-DR\" , bins = 64 ) + scale_x_flowjo_biexp () + scale_y_flowjo_fasinh () Let\u2019s practice - R markdown If a data analysis project involves many steps and generation of various plots, one of the easy and very practical ways to bundle and organize all steps of analysis together is to use R markdown files to generate PDF or html reports. These reports both display the R code used as well as the output generated, such as graphics, tables, statistical test results, \u2026 The difference between an R script and an R markdown file, is that the code is organized within chunks in the R markdown file. In between the chunks, the user can write text that contains information about the analysis. To create an R markdown file, go to File > New File > R markdown. Add a name. This will create a new file that already has some example content. As you can see, the R code is organized in chunks highlighed in grey, with details written as free text in between the chunks. We can see that the pound sign (#) is used outside of the R code chunks. In this case, the # symbol does not correspond to a comment, but will indicate header levels for the titles and subtitles within your final document obtained after report generation. Once the Rmd is ready, the report can be generated by hitting the \u201cKnit\u201d button at the top of the window. The example Rmd generates the following html report (saved in the same folder as the Rmd file by default), that shows both the code and the resulting output: You can find a short video that introduces some of the principles of R markdown on Youtube , from the beginning up to minute 23:30. Starting at minute 23:30, this video also introduces ggplot2. If you would like to practice creating your own R markdown, modify the one that is generated with the example content when you select File > New File > R Markdown. 1) Create a new Rmd file with the following options at the top (in the top YAML instructions within the 2 dash sequences \u201c- - -\u201c) Title: \u00abLet\u2019s practice\u00bb Author: your name Select the \u00abuse current date when rendering object\u00bb option Default output format: HTML 2) We will repeat exercise 7, but this time by creating a report: Within an R code chunk, import the data from the file clinical_data_mod.csv, convert gender and response to treatment to factors and compute the BMI of patients in a separate code chunk called \u201cprepare_data\u201d. Change the chunk options so that code will not appear in the output. Then, create a new code chunk for each plot. Make sure the plot is centered. Add a header (preceded by the # symbols outside of the code chunks) before each plot with some suggestive plot title. 3) Save the Rmd file and produce the html document by \u00abknitting\u00bb it. Download solution Rmd file For tweaking your reports, such as chosing different output formats, or hiding or showing the code within the report, we recommend that you consult the R markdown documentation provided in this Definite guide eBook . Another useful resource is RStudio\u2019s R Markdown tutorial . Let\u2019s practice - R markdown bis Create an R markdown file and knit to an html report the flow cytometry data analysis performed in Exercise number 9. Proceed similarly, creating a code chunk where you load the libraries, import and pre-process the data, and create a separate code chunk for every plot. Download solution Rmd file Let\u2019s practice - Introduction to statistics with R. The SIB course \u201cFirst Steps with R in life sciences\u201d provides additional material to perform statistics with R. The slides introducing statistics with R can be found here on the course material github page . The R code to run Wilcoxon or T tests can be found here (ex.9) using source data that can be found here . The R code to run a linear model can be found here (ex.10) . Feel free to try it out! End of Day 2, good job!","title":"Exercises"},{"location":"introR/day2/exercises_d2/#lets-practice-7","text":"Import the clinical data from the file clinical_data_mod.csv. This files contains the same data as clinical_data.csv and in addition, one more column. 1) Run str() to check your data frame: did it load correctly? 2) Convert gender and response_to_treatment to factor variables. 3) Plot a histogram of patient weight and customize it with colours, labels, title. 4) Make a scatter plot of height against patient weights using the function plot(). Function arguments: use solid circles as plotting symbol add a title customize the axis labels (\u201cWeight [kg]\u201d, \u201cHeight [m]\u201d) color the points by gender. Add a legend for the gender. Fit a trend line using the function abline(). 5) Create a new column called \u201cBMI\u201d and compute the BMI of patients from their weight and height 6) Make boxplots of BMI from patients with different responses to treatment. Customize with title, labels, colors. Add points to the boxplots to show the individual values. 7) Optional: Repeat 6 with stage, instead of response to treatment. Hint: what kind of variable is stage? Answer clinical_data <- read.table ( \"course_datasets/clinical_data_mod.csv\" , header = TRUE , sep = \",\" ) # define classes for columns str ( clinical_data ) # 2) Convert gender and response_to_treatment to factor variables # define the order of factor levels clinical_data $ gender <- factor ( clinical_data $ gender ) clinical_data $ response_to_treatment <- factor ( clinical_data $ response_to_treatment , levels = c ( \"PD\" , \"SD\" , \"PR\" , \"CR\" )) # 3) Plot an histogram of patient weight and customize it with colours, labels, title and represent the density line on top. hist ( clinical_data $ weight , freq = FALSE , breaks = 8 , main = \"Patient Weight\" , col = \"orange\" , xlab = \"Weight [kg]\" ) # lines(density(clinical_data$weight), col='blue') # Note: freq=FALSE makes the histogram density based, which makes it scale well with the density line # 4) Make a scatter plot of height against patient weights using the function plot(). # Function arguments: # - use solid circles as plotting symbol # - add a title # - customise the axis labels (\u201cWeight [kg]\u201d, \u201cHeight [m]\u201d) # - colour the points by gender. # Add a legend for the gender. plot ( clinical_data $ weight , clinical_data $ height , pch = 19 , main = \"Weight vs Height in Patients\" , xlab = \"Weight [kg]\" , ylab = \"Height [m]\" , col = c ( \"orange\" , \"blue\" )[ clinical_data $ gender ] ) legend ( \"bottomright\" , legend = levels ( clinical_data $ gender ), col = c ( \"orange\" , \"blue\" ), pch = 19 ) abline ( lm ( clinical_data $ height ~ clinical_data $ weight ), col = \"black\" , lwd = 1.5 ) # 5) Compute the BMI = Weight / Height^2 clinical_data $ BMI <- clinical_data $ weight / ( clinical_data $ height ^ 2 ) # 6) Make boxplots of BMIs from patients with different responses to treatment. Customize with title, labels, colors. boxplot ( BMI ~ response_to_treatment , data = clinical_data , col = c ( \"red\" , \"orange\" , \"green\" , \"blue\" ), main = \"BMI by level of Response to treatment\" , xlab = \"Response to treatment\" , ylab = \"BMI\" ) points ( BMI ~ response_to_treatment , data = clinical_data ) # 7) Optional: Repeat 6 with BMI and stage, instead of weight and gender. clinical_data $ stage <- factor ( clinical_data $ stage , levels = c ( \"I\" , \"II\" , \"III\" , \"IV\" )) boxplot ( BMI ~ stage , data = clinical_data , col = c ( \"blue\" , \"green\" , \"orange\" , \"red\" ), main = \"Patient BMI by Stage\" , xlab = \"Stage\" , ylab = \"BMI\" ) points ( BMI ~ stage , data = clinical_data ) getwd () # check where you are. If you didn't change anything, you will be in the folder with the .Rproj file (rproject root)","title":"Let's practice 7"},{"location":"introR/day2/exercises_d2/#lets-practice-8","text":"1) Create a multi-panel figure with the four graphics (3, 4, 6 and 7 from the previous exercise) on one page, exporting the figure to a pdf file with paper size A4. Set width and height arguments in the call to pdf() to make it look nice. 2) Optional: Export the histogram (3 from previous exercise) to a png file. Set the width and height arguments in the call to png() to make it look nice. Answer # 1) Make a multi-panel figure with the four graphics on one page, exporting the figure to a png file. # Set width and height arguments in the call to png() to make it look nice. pdf ( \"clinical_data_plots.pdf\" , width = 7 , height = 7 , paper = \"a4\" ) # we want to put 4 plots on the same panel -> 2 rows and 2 columns par ( mfrow = c ( 2 , 2 )) # Plot 1 hist ( clinical_data $ weight , freq = FALSE , breaks = 8 , main = \"Patient Weight\" , col = \"orange\" , xlab = \"Weight [kg]\" ) lines ( density ( clinical_data $ weight ), col = 'blue' ) # Plot 2 plot ( clinical_data $ weight , clinical_data $ height , pch = 19 , main = \"Weight vs Height in Patients\" , xlab = \"Weight [kg]\" , ylab = \"Height [m]\" , col = c ( \"orange\" , \"blue\" )[ clinical_data $ gender ] ) legend ( \"bottomright\" , legend = levels ( clinical_data $ gender ), col = c ( \"orange\" , \"blue\" ), pch = 19 ) abline ( lm ( clinical_data $ height ~ clinical_data $ weight ), col = \"black\" , lwd = 1.5 ) # Plot 3 boxplot ( BMI ~ response_to_treatment , data = clinical_data , col = c ( \"red\" , \"orange\" , \"green\" , \"blue\" ), main = \"BMI by level of Response to treatment\" , xlab = \"Response to treatment\" , ylab = \"BMI\" ) points ( BMI ~ response_to_treatment , data = clinical_data ) # Plot 4 boxplot ( BMI ~ stage , data = clinical_data , col = c ( \"blue\" , \"green\" , \"orange\" , \"red\" ), main = \"Patient BMI by Stage\" , xlab = \"Stage\" , ylab = \"BMI\" ) points ( BMI ~ stage , data = clinical_data ) dev.off () # 2) Optional: Export the histogram (3 from previous exercise) to a png file. # Set width and height arguments in the call to png() to make it look nice. # png: width and height are in pixels by default png ( \"hist_weight.png\" , width = 800 , height = 600 ) hist ( clinical_data $ weight , freq = FALSE , breaks = 8 , main = \"Patient Weight\" , col = \"orange\" , xlab = \"Weight [kg]\" ) lines ( density ( clinical_data $ weight ), col = 'blue' ) dev.off () Bonus Create plots with ggplot2 . ggplot2 is a package that allows you to create graphics by adding customization \u201clayers\u201d one after the other. You first provide the data, tell ggplot2 how to map variables to aesthetics (i.e. the variables you want to have on the x and y coordinates), what plot type to use, and it provides some default colors for the categorical variables, and automatic legend positioning. Everything can then be further customized by the user by adding additional layers using ggplot2 functions. library ( ggplot2 ) # Import data: clinical_data <- read.table ( \"course_datasets/clinical_data_mod.csv\" , header = TRUE , sep = \",\" ) # define classes for columns str ( clinical_data ) # Convert gender to factor variables clinical_data $ gender <- factor ( clinical_data $ gender ) # Compute the BMI = Weight / Height^2 clinical_data $ BMI <- clinical_data $ weight / ( clinical_data $ height ^ 2 ) # Simple boxplot of BMI vs stage ggplot ( data = clinical_data , aes ( x = stage , y = BMI )) + geom_boxplot () # Boxplot of BMI vs stage, coloring according to stage # With legend: ggplot ( data = clinical_data , aes ( x = stage , y = BMI , color = stage )) + geom_boxplot () # Boxplot of BMI vs stage, coloring according to stage, flipping orientation ggplot ( data = clinical_data , aes ( x = stage , y = BMI , color = stage )) + geom_boxplot () + coord_flip () # Without legend: ggplot ( data = clinical_data , aes ( x = stage , y = BMI , color = stage )) + geom_boxplot () + theme ( legend.position = \"none\" ) # Scatter plot of weight vs height, coloring by gender ggplot ( data = clinical_data , aes ( x = weight , y = height , color = gender )) + geom_point () # Compare plot generated earlier with base R to the one with ggplot2: # Reproduce Plot 2 of exercise 8 plot ( clinical_data $ weight , clinical_data $ height , pch = 19 , main = \"Weight vs Height in Patients\" , xlab = \"Weight [kg]\" , ylab = \"Height [m]\" , col = c ( \"orange\" , \"blue\" )[ clinical_data $ gender ]) legend ( \"bottomright\" , legend = levels ( clinical_data $ gender ), col = c ( \"orange\" , \"blue\" ), pch = 19 ) abline ( lm ( clinical_data $ height ~ clinical_data $ weight ), col = \"black\" , lwd = 1.5 ) # Same plot with ggplot2 # Scatter plot of weight vs height, coloring by gender ggplot ( data = clinical_data , aes ( x = weight , y = height , color = gender )) + geom_point () + scale_color_manual ( values = c ( \"female\" = \"orange\" , \"male\" = \"blue\" )) + ggtitle ( \"Weight vs Height in Patients\" ) + xlab ( \"Weight [kg]\" ) + ylab ( \"Height [m]\" ) + theme_bw () + geom_smooth ( method = \"lm\" , formula = y ~ x , se = TRUE ) # display confidence interval around smoothed curve # Create a separate plot for males and females: # Use Facet wrap: separate the plots according to a categorical (factor) variable ggplot ( data = clinical_data , aes ( x = weight , y = height , color = gender )) + geom_point () + scale_color_manual ( values = c ( \"female\" = \"orange\" , \"male\" = \"blue\" )) + ggtitle ( \"Weight vs Height in Patients\" ) + xlab ( \"Weight [kg]\" ) + ylab ( \"Height [m]\" ) + theme_bw () + geom_smooth ( method = \"lm\" , formula = y ~ x , se = TRUE ) + facet_wrap ( ~ gender ) ### Multi panel figures with ggplot2 # save each plot in an object, create 2 plots that are the same except for the color of the dots p1 <- ggplot ( data = clinical_data , aes ( x = weight , y = height , color = gender )) + geom_point () + scale_color_manual ( values = c ( \"female\" = \"orange\" , \"male\" = \"blue\" )) + ggtitle ( \"Weight vs Height in Patients\" ) + xlab ( \"Weight [kg]\" ) + ylab ( \"Height [m]\" ) + theme_bw () p2 <- ggplot ( data = clinical_data , aes ( x = weight , y = height , color = gender )) + geom_point () + scale_color_manual ( values = c ( \"female\" = \"turquoise\" , \"male\" = \"plum\" )) + ggtitle ( \"Weight vs Height in Patients\" ) + xlab ( \"Weight [kg]\" ) + ylab ( \"Height [m]\" ) + theme_bw () # install the cowplot package to arrange several plots on a single page # install.packages(\"cowplot\") library ( cowplot ) plot_grid ( p1 , p2 , nrow = 1 )","title":"Let's practice 8"},{"location":"introR/day2/exercises_d2/#lets-practice-9","text":"In this exercise we will use a 36-color spectral flow cytometry dataset from a study performed in the context of Covid-19 research. Only a subset from 4 healthy donors will be used. For each healthy donor, there are three time points, as indicated in the FCS file names (day 0, day 7, day 14). Data was downloaded through the Flow Repository database, FR-FCM-Z3WR . FCS files were pre-gated on live CD3+CD19-T cells in FlowJo. Create a new script in which you will: 1) Import the FCS files (located in course_datasets/FR_FCM_Z3WR/). Do not transform or truncate the values. 2) Create a data frame with the list of channels and corresponding antigens, and plot it. Hint: get the antigens from the parameters of one of the flowFrame in the set 3) Convert the channel names in the expression matrices to the corresponding antigen names (where applicable) 4) Add a new column to the phenotypic data with the time point of the sample. Plot the phenotypic data 5) Create a bivariate density plot showing \u00abFSC-H\u00bb againts \u00abHLA-DR\u00bb for all samples from day 0. Apply a flowJo inverse hyperbolic sine scale to the y axis (\u00abHLA-DR\u00bb) Answer # load packages library ( flowCore ) library ( ggcyto ) # 1) Import the FCS files (course_datasets/FR_FCM_Z3WR/). # Do not transform or truncate the values. # path to the directory with the fcs files fcs.dir <- file.path ( \"course_datasets/FR_FCM_Z3WR/\" ) # read fcs files into a flowSet fcs_data <- read.flowSet ( path = fcs.dir , pattern = \"*.fcs\" , transformation = FALSE , truncate_max_range = FALSE ) #2) Create a data frame with the list of channels and corresponding antigens, and plot it. #Hint: get the antigens from the parameters of one of the flowFrame in the set channels <- colnames ( fcs_data ) antigen <- pData ( parameters ( fcs_data [[ 1 ]])) $ desc panel <- data.frame ( channels = channels , antigen = antigen ) # View the panel in the console panel #3) Convert the channel names in the expression matrices to the # corresponding antigen names (where applicable) colnames ( fcs_data )[ ! is.na ( antigen )] <- antigen [ ! is.na ( antigen )] # check head ( exprs ( fcs_data [[ 1 ]])[, c ( 5 : 10 )]) #4) Add a new column to the phenotypic data with the time point of the sample # check sample names sampleNames ( fcs_data ) # [1] \"0E1F8E_0.fcs\" \"0E1F8E_14.fcs\" \"0E1F8E_7.fcs\" \"180E1A_0.fcs\" \"180E1A_14.fcs\" \"180E1A_7.fcs\" # [7] \"1A9B20_0.fcs\" \"1A9B20_14.fcs\" \"1A9B20_7.fcs\" \"61BBAD_0.fcs\" \"61BBAD_14.fcs\" \"61BBAD_7.fcs\" # add column with time point pData ( fcs_data ) $ time_point <- rep ( c ( \"D0\" , \"D14\" , \"D7\" ), 4 ) # View the phenotypic data pData ( fcs_data ) # 5) Create a bivariate density plot showing \"FSC-H\" against \"HLA-DR\" for all samples from day 0. # Apply a flowJO inverse hyperbolic sine scale to the y axis (\"HLA-DR\") # split by time point fcs_data.split <- split ( fcs_data , pData ( fcs_data ) $ time_point ) # create the bivariate density plot autoplot ( fcs_data.split $ D0 , x = \"FSC-H\" , y = \"HLA-DR\" , bins = 64 ) + scale_x_flowjo_biexp () + scale_y_flowjo_fasinh ()","title":"Let's practice 9"},{"location":"introR/day2/exercises_d2/#lets-practice-r-markdown","text":"If a data analysis project involves many steps and generation of various plots, one of the easy and very practical ways to bundle and organize all steps of analysis together is to use R markdown files to generate PDF or html reports. These reports both display the R code used as well as the output generated, such as graphics, tables, statistical test results, \u2026 The difference between an R script and an R markdown file, is that the code is organized within chunks in the R markdown file. In between the chunks, the user can write text that contains information about the analysis. To create an R markdown file, go to File > New File > R markdown. Add a name. This will create a new file that already has some example content. As you can see, the R code is organized in chunks highlighed in grey, with details written as free text in between the chunks. We can see that the pound sign (#) is used outside of the R code chunks. In this case, the # symbol does not correspond to a comment, but will indicate header levels for the titles and subtitles within your final document obtained after report generation. Once the Rmd is ready, the report can be generated by hitting the \u201cKnit\u201d button at the top of the window. The example Rmd generates the following html report (saved in the same folder as the Rmd file by default), that shows both the code and the resulting output: You can find a short video that introduces some of the principles of R markdown on Youtube , from the beginning up to minute 23:30. Starting at minute 23:30, this video also introduces ggplot2. If you would like to practice creating your own R markdown, modify the one that is generated with the example content when you select File > New File > R Markdown. 1) Create a new Rmd file with the following options at the top (in the top YAML instructions within the 2 dash sequences \u201c- - -\u201c) Title: \u00abLet\u2019s practice\u00bb Author: your name Select the \u00abuse current date when rendering object\u00bb option Default output format: HTML 2) We will repeat exercise 7, but this time by creating a report: Within an R code chunk, import the data from the file clinical_data_mod.csv, convert gender and response to treatment to factors and compute the BMI of patients in a separate code chunk called \u201cprepare_data\u201d. Change the chunk options so that code will not appear in the output. Then, create a new code chunk for each plot. Make sure the plot is centered. Add a header (preceded by the # symbols outside of the code chunks) before each plot with some suggestive plot title. 3) Save the Rmd file and produce the html document by \u00abknitting\u00bb it. Download solution Rmd file For tweaking your reports, such as chosing different output formats, or hiding or showing the code within the report, we recommend that you consult the R markdown documentation provided in this Definite guide eBook . Another useful resource is RStudio\u2019s R Markdown tutorial .","title":"Let's practice - R markdown"},{"location":"introR/day2/exercises_d2/#lets-practice-r-markdown-bis","text":"Create an R markdown file and knit to an html report the flow cytometry data analysis performed in Exercise number 9. Proceed similarly, creating a code chunk where you load the libraries, import and pre-process the data, and create a separate code chunk for every plot. Download solution Rmd file","title":"Let's practice - R markdown bis"},{"location":"introR/day2/exercises_d2/#lets-practice-introduction-to-statistics-with-r","text":"The SIB course \u201cFirst Steps with R in life sciences\u201d provides additional material to perform statistics with R. The slides introducing statistics with R can be found here on the course material github page . The R code to run Wilcoxon or T tests can be found here (ex.9) using source data that can be found here . The R code to run a linear model can be found here (ex.10) . Feel free to try it out! End of Day 2, good job!","title":"Let's practice - Introduction to statistics with R."}]}